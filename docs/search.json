[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Portfolio",
    "section": "",
    "text": "Oct 21, 2022\n\n\nKarol Orozco\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOct 4, 2022\n\n\nKarol Orozco\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOct 1, 2022\n\n\nKarol Orozco\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Instacart/index.html",
    "href": "posts/Instacart/index.html",
    "title": "Instacart",
    "section": "",
    "text": "The data analyzed came for kaggle, https://www.kaggle.com/c/instacart-market-basket-analysis/data. The dataset is anonymized and contains a sample of over 3 million grocery orders from more than 200,000 Instacart users\nOnce the dataset is downloaded, it weighs 200.7 MB in zip format. Once unzipped, six files appear:\n\ndepartments.csv: Collect name and id for different departments.\naisle.csv: That collects the corridors and the different sections.\nproducts.csv: Collect all the products that are for sale in the store.\norders.csv: Collect all the orders made by customers, or which is the same, all the shopping carts (Market_Basket).\norder_products_prior.csv: Collect the products that were purchased in an order and all the customer’s purchase history throughout that year.\norder_products_train.csv: Collect the products that were purchased in an order reflecting the last basket purchased by each customer.\n\nFor this analysis, we will use the order_products_train.csv, which offers a data sample of the order_products_prior.csv"
  },
  {
    "objectID": "posts/Instacart/index.html#prepare-and-analyze-the-data",
    "href": "posts/Instacart/index.html#prepare-and-analyze-the-data",
    "title": "Instacart",
    "section": "Prepare and Analyze the Data",
    "text": "Prepare and Analyze the Data\nLoad the data: Departments, order_products, orders, products and aisles\n\n\nShow the code\ndepartments <- read.csv(\"C:/Users/karol/Desktop/DATA/INSTA/departments.csv\")\norder_products <- read.csv(\"C:/Users/karol/Desktop/DATA/INSTA/order_products__train.csv\")\norders <- read.csv(\"C:/Users/karol/Desktop/DATA/INSTA/orders.csv\")\nproducts <- read.csv(\"C:/Users/karol/Desktop/DATA/INSTA/products.csv\")\naisles <- read.csv(\"C:/Users/karol/Desktop/DATA/INSTA/aisles.csv\")\n\n\n\nDepartments\n\n\nShow the code\nglimpse(departments)\n\n\nRows: 21\nColumns: 2\n$ department_id <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ department    <chr> \"frozen\", \"other\", \"bakery\", \"produce\", \"alcohol\", \"inte…\n\n\n\n\nOrder Products\n\n\nShow the code\nglimpse(order_products)\n\n\nRows: 1,384,617\nColumns: 4\n$ order_id          <int> 1, 1, 1, 1, 1, 1, 1, 1, 36, 36, 36, 36, 36, 36, 36, …\n$ product_id        <int> 49302, 11109, 10246, 49683, 43633, 13176, 47209, 220…\n$ add_to_cart_order <int> 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2…\n$ reordered         <int> 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0…\n\n\n\n\nOrders\n\n\nShow the code\nglimpse(orders)\n\n\nRows: 3,421,083\nColumns: 7\n$ order_id               <int> 2539329, 2398795, 473747, 2254736, 431534, 3367…\n$ user_id                <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2,…\n$ eval_set               <chr> \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"p…\n$ order_number           <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1, 2, 3, 4, …\n$ order_dow              <int> 2, 3, 3, 4, 4, 2, 1, 1, 1, 4, 4, 2, 5, 1, 2, 3,…\n$ order_hour_of_day      <int> 8, 7, 12, 7, 15, 7, 9, 14, 16, 8, 8, 11, 10, 10…\n$ days_since_prior_order <dbl> NA, 15, 21, 29, 28, 19, 20, 14, 0, 30, 14, NA, …\n\n\n\n\nProducts\n\n\nShow the code\nglimpse(products)\n\n\nRows: 49,688\nColumns: 4\n$ product_id    <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ product_name  <chr> \"Chocolate Sandwich Cookies\", \"All-Seasons Salt\", \"Robus…\n$ aisle_id      <int> 61, 104, 94, 38, 5, 11, 98, 116, 120, 115, 31, 119, 11, …\n$ department_id <int> 19, 13, 7, 1, 13, 11, 7, 1, 16, 7, 7, 1, 11, 17, 18, 19,…\n\n\n\n\nAisles\n\n\nShow the code\nglimpse(aisles)\n\n\nRows: 134\nColumns: 2\n$ aisle_id <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ aisle    <chr> \"prepared soups salads\", \"specialty cheeses\", \"energy granola…\n\n\n\nCombining and Transforming the data\n\n\nShow the code\norders$order_hour_of_day <- as.numeric(orders$order_hour_of_day)\n\nproducts <- products%>% mutate(category =  ifelse(grepl(\"Organic\", products$product_name), \"Organic\",  \"Non-organic\"))\ndf <- products %>% group_by(department_id, aisle_id, product_id, product_name, category) %>% dplyr::summarize(n=n())\n\n\ndf <- df %>% left_join(departments,by=\"department_id\")\ndf<-  df %>% left_join(aisles,by=\"aisle_id\")\ndata <- merge(x= order_products,y= df, by= \"product_id\")\ndata <- merge(x= data, y= orders, by= \"order_id\")\n\n\nproducts <- products %>% mutate(product_name = as.factor(product_name))\n\naisles <- aisles %>% mutate(aisle = as.factor(aisle))\ndepartments <- departments %>% mutate(department = as.factor(department))\ndata <- data %>% mutate(product_name = as.factor(product_name))\ndata <- data %>% mutate(order_id = as.character(order_id))\ndata <- data %>% mutate(add_to_cart_order = as.factor(add_to_cart_order))\ndata <- data %>% mutate(reordered = as.factor(reordered))\n\n\n\n\nShow the code\nstr(data)\n\n\n'data.frame':   1384617 obs. of  17 variables:\n $ order_id              : chr  \"1\" \"1\" \"1\" \"1\" ...\n $ product_id            : int  13176 49302 22035 11109 47209 49683 43633 10246 43086 39612 ...\n $ add_to_cart_order     : Factor w/ 80 levels \"1\",\"2\",\"3\",\"4\",..: 6 1 8 2 7 4 5 3 4 1 ...\n $ reordered             : Factor w/ 2 levels \"0\",\"1\": 1 2 2 2 1 1 2 1 2 1 ...\n $ department_id         : int  4 16 16 16 4 4 15 4 4 16 ...\n $ aisle_id              : int  24 120 21 108 24 83 95 83 123 2 ...\n $ product_name          : Factor w/ 39123 levels \"#2 Coffee Filters\",..: 2635 4507 25657 22359 23761 9089 18248 22851 34372 14425 ...\n $ category              : chr  \"Organic\" \"Non-organic\" \"Organic\" \"Organic\" ...\n $ n                     : int  1 1 1 1 1 1 1 1 1 1 ...\n $ department            : chr  \"produce\" \"dairy eggs\" \"dairy eggs\" \"dairy eggs\" ...\n $ aisle                 : chr  \"fresh fruits\" \"yogurt\" \"packaged cheese\" \"other creams cheeses\" ...\n $ user_id               : int  112108 112108 112108 112108 112108 112108 112108 112108 79431 79431 ...\n $ eval_set              : chr  \"train\" \"train\" \"train\" \"train\" ...\n $ order_number          : int  4 4 4 4 4 4 4 4 23 23 ...\n $ order_dow             : int  4 4 4 4 4 4 4 4 6 6 ...\n $ order_hour_of_day     : num  10 10 10 10 10 10 10 10 18 18 ...\n $ days_since_prior_order: num  9 9 9 9 9 9 9 9 30 30 ...\n\n\n\n\n\nData Exploration\nMaximum number of orders are placed between 9:00am and 4:00pm on Sunday and Monday. There is also a big number of orders during Friday and Saturday.\n\n\nShow the code\nday_week <- orders %>%\n    mutate(day = as.factor(order_dow)) %>%\n    mutate(hour = as.factor(order_hour_of_day)) %>%\n    group_by(day,hour) %>%\n    dplyr::summarise(count = n()) %>%\n    arrange(desc(count))\n\nday_weekp <-day_week %>%\n    ggplot(aes(x=day, y=hour))+\n    geom_tile(aes(fill=count), colour = \"white\") + \n  \n    scale_fill_gradient(name= \"Number of\\nOrders\", \n                        low = \"#FFF5EE\",\n                        high = \"#CC5500\")+\n    scale_x_discrete( position = \"top\",\n                    breaks = c(\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\"),\n                    label = c(\"Sunday\", \"Monday\", \"Tuesday\",\n                              \"Wednesday\",\"Thursday\", \"Friday\", \"Saturday\"),\n                    expand=c(0,0))+\n    scale_y_discrete( \n                    breaks = c(\"0\", \"6\", \"12\", \"18\", \"23\"),\n                    label = c(\"12am\", \"6am\", \"12pm\", \"6pm\", \"11pm\"),\n                    expand=c(0,0))+\n  \n    labs(title=\"Which Day and What Time Do Customers Order the Most?\",\n            x=\"\", \n            y=\"\")+\n  \n    ggpubr::theme_pubclean()+\n    theme(\n      \n    axis.line=element_blank(),                                               \n    axis.ticks=element_line(size=0.4),\n    axis.text = element_text(size= 10),\n\n    plot.background=element_blank(),         \n    plot.title = element_text(size =10, hjust = 0.50, vjust = 1),\n    plot.caption = element_text(hjust = 0, size = 5, \n                                margin = unit(c(0.5, 0.5, 0.5, 0.5), \"cm\")),\n\n    \n    panel.grid = element_blank(),\n    \n    legend.position = \"bottom\",\n    legend.title = element_text(size= 9),\n    legend.margin=margin(grid::unit(0,\"cm\")),\n    legend.key.width=grid::unit(2,\"cm\"),\n    legend.key.height=grid::unit(0.2,\"cm\")\n)\n\nday_weekp\n\n\n\n\n\nSo, from the above graph, its clear that Maximum no of orders are placed between 10:00AM and 5:00PM on Sunday and Monday.\nActions: Develop strategies to increase sales during the quietest days of the week:\n\nOffer discounts on certain items.\nOffer free delivery with orders over a specific dollar amount.\n\nPositive note: Customers can shop on a Wednesday or Thursday, and most likely, they will never encounter “out of stock” items or delivery/pick delays.\n\n\nShow the code\ndata%>%\n  group_by(days_since_prior_order) %>%\n  dplyr::summarise(torders = n())%>%\n  mutate(color= ifelse(torders>100000, \"#CC5500\", \"gray\"))%>%\n\n  ggplot(aes(x = days_since_prior_order, y= torders, fill= color)) + \n  geom_col(show.legend = FALSE) +\n  scale_x_continuous(breaks = seq(0, 30, 5))+\n  scale_y_continuous(labels = scales::comma)+\n  scale_fill_manual(\"\", values = c(\"#CC5500\", \"gray\"))+\n  labs(x= \"Days Since Prior Order\",\n       y= \"Number of Orders\",\n       title = \"How Many Days Do Customer Wait to Place a New Order?\")+\n  \n ggpubr::theme_pubclean()+\n theme(plot.title = element_text(size =10, hjust = 0.50, vjust = 1),\n           axis.text = element_text(size= 10)) \n\n\n\n\n\nMost customers wait approximately 30 days to place their next order, followed by another majority of customers who wait seven days to make their next purchase.\n\nBestsellers Products\n\n\nShow the code\ntype <- data   %>%\n    group_by(product_id)%>% \n    dplyr::summarize(count = n()) %>% \n    top_n(20, wt = count) %>%\n    left_join(select(products, product_id, product_name, category), by=\"product_id\") %>%\n    arrange(desc(count))\n\n \n\nbest <- type %>% \nggplot(aes(x=reorder(product_name,count), y=count, color= category, text= paste0(product_name, \", Total Orders:\", count)))+    \n  geom_point(size= 2)+\n    geom_segment(aes(x=reorder(product_name,count), \n                     xend=reorder(product_name,count), \n                     y=0, \n                     yend=count), size=0.8)+\n  \n    scale_y_continuous(labels = scales::comma) +\n  \n      labs(title=\"Bestsellers Products\",\n           subtitle = \"Organic vs Non-Organic\",\n           y=\"\", \n           x=\"\", \n           legend = \"\")+\n     scale_color_manual(\"\", values = c(\"#CC5500\", \"#0AAD0A\"))+\n\n      theme(\n       axis.text.x= element_text( size= 7),\n       axis.text.y= element_text( size= 8),\n\n       panel.grid.major.x = element_blank(),\n       panel.grid.major.y = element_blank(),\n       panel.grid.minor.y = element_blank(),\n       panel.grid = element_line(color = \"#e5e5e5\"))+\n  \n     ggpubr::theme_pubclean()+\n     coord_flip()\n\nggplotly(best, tooltip = \"text\")\n\n\n\n\n\n\nThe highest ordered products are Banana, Bag of Organic Bananas, Organic Strawberries and Organic Baby Spinach. So to increase the sale of Strawberries the retailer can put it near the Bananas.\n\n\nShow the code\nProd_portf <- data %>% \n  group_by(product_id) %>% \n  dplyr::summarize(count=n()) %>% \n  left_join(products,by=\"product_id\") %>% \n  ungroup() %>% \n  group_by(department_id,aisle_id) %>% \n  dplyr::summarize(sumcount = sum(count)) %>% \n  left_join(df, by = c(\"department_id\", \"aisle_id\")) %>% \n  mutate(onesize = 1)\n\n\n## Treemap\n\np <-  treemap(Prod_portf,\n              index=c(\"department\",\"aisle\"),\n        vSize=\"n\",\n        vColor= \"department\",\n        type=\"index\",\n        \n        #Main\n        palette= \"Set3\",\n        title=\"Product Portfolio\",\n        sortID=\"-sumcount\")\n\n\n\n\nShow the code\nd3tree2( p,  rootname = \"Portfolio\" )"
  },
  {
    "objectID": "posts/Regression/Analyzing Employee Turnover.html",
    "href": "posts/Regression/Analyzing Employee Turnover.html",
    "title": "Analyzing Employee Turnover",
    "section": "",
    "text": "You work for the human capital department of a large corporation. The Board is worried about the relatively high turnover, and your team must look into ways to reduce the number of employees leaving the company. The team needs to understand better the situation, which employees are more likely to leave, and why. Once it is clear what variables impact employee churn, you can present your findings along with your ideas on how to attack the problem.\n\n\nCreate a report that covers the following:\n\nWhich department has the highest employee turnover? Which one has the lowest?\nInvestigate which variables seem to be better predictors of employee departure.\nWhat recommendations would you make regarding ways to reduce employee turnover?"
  },
  {
    "objectID": "posts/Regression/Analyzing Employee Turnover.html#import-libraries",
    "href": "posts/Regression/Analyzing Employee Turnover.html#import-libraries",
    "title": "Analyzing Employee Turnover",
    "section": "2. Import Libraries",
    "text": "2. Import Libraries\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(skimr)\nlibrary(janitor)\nlibrary(knitr)\nlibrary(radiant)\nlibrary(colorspace)\nlibrary(gridExtra)\nlibrary(jtools)\nlibrary(dplyr)\nlibrary(MASS)"
  },
  {
    "objectID": "posts/Regression/Analyzing Employee Turnover.html#prepare-and-analyze-the-data",
    "href": "posts/Regression/Analyzing Employee Turnover.html#prepare-and-analyze-the-data",
    "title": "Analyzing Employee Turnover",
    "section": "3. Prepare and Analyze the Data",
    "text": "3. Prepare and Analyze the Data\nThe department has assembled data on almost 10,000 employees. The team used information from exit interviews, performance reviews, and employee records.\n\n\n\nThe variables are defined as follow:\n\n“department” - the department the employee belongs to.\n“promoted” - 1 if the employee was promoted in the previous 24 months, 0 otherwise.\n“review” - the composite score the employee received in their last evaluation.\n“projects” - how many projects the employee is involved in.\n“salary” - for confidentiality reasons, salary comes in three tiers: low, medium, high.\n“tenure” - how many years the employee has been at the company.\n“satisfaction” - a measure of employee satisfaction from surveys.\n“bonus” - 1 if the employee received a bonus in the previous 24 months, 0 otherwise.\n“avg_hrs_month” - the average hours the employee worked in a month.\n“left” - “yes” if the employee ended up leaving, “no” otherwise.\n\n\n\n\nData summary\n\n\nName\nempl_turnover\n\n\nNumber of rows\n9540\n\n\nNumber of columns\n10\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ndepartment\n0\n1\n2\n11\n0\n10\n0\n\n\nsalary\n0\n1\n3\n6\n0\n3\n0\n\n\nleft\n0\n1\n2\n3\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\npromoted\n0\n1\n0.03\n0.17\n0.00\n0.00\n0.00\n0.00\n1.00\n▇▁▁▁▁\n\n\nreview\n0\n1\n0.65\n0.09\n0.31\n0.59\n0.65\n0.71\n1.00\n▁▃▇▃▁\n\n\nprojects\n0\n1\n3.27\n0.58\n2.00\n3.00\n3.00\n4.00\n5.00\n▁▇▁▅▁\n\n\ntenure\n0\n1\n6.56\n1.42\n2.00\n5.00\n7.00\n8.00\n12.00\n▁▇▇▂▁\n\n\nsatisfaction\n0\n1\n0.50\n0.16\n0.00\n0.39\n0.50\n0.62\n1.00\n▁▅▇▅▁\n\n\nbonus\n0\n1\n0.21\n0.41\n0.00\n0.00\n0.00\n0.00\n1.00\n▇▁▁▁▂\n\n\navg_hrs_month\n0\n1\n184.66\n4.14\n171.37\n181.47\n184.63\n187.73\n200.86\n▁▆▇▂▁\n\n\n\n\n\n\nThere is no missing data in the data set.\nEmployees are involved between 2 to 5 projects\nEmployees have been at the company between 2 to 12 years, with an average of 6.5 years\nThe average satisfaction rate in 50.41% for all employees\nThe average worked hours per month ranged from 171.37 to 200.86 hours\nThere are some data types that need to be changed. For example, “left” is a character variable. To convert it into a quantity that takes values of zero and one, I’ll convert it into a variable of type factor with two levels: No and Yes. Later, I will use as.numeric() to convert the observations to a number, one or two. I then subtract one to get a variable that takes values zero or one and stores it as left.Numeric\n\n\n\nShow the code\nempl_turnover$department <- as.factor(empl_turnover$department)\nempl_turnover$left<- as.factor(empl_turnover$left)\nempl_turnover$promoted<- as.factor(empl_turnover$promoted)\nempl_turnover$bonus<- as.factor(empl_turnover$bonus)\nempl_turnover$salary<- factor(empl_turnover$salary, levels = c(\"low\", \"medium\", \"high\"))\nempl_turnover$left.Numeric <- as.numeric(as.factor(empl_turnover$left))-1\n\n\nglimpse(empl_turnover)\n\n\nRows: 9,540\nColumns: 11\n$ department    <fct> operations, operations, support, logistics, sales, IT, a…\n$ promoted      <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ review        <dbl> 0.5775687, 0.7518997, 0.7225484, 0.6751583, 0.6762032, 0…\n$ projects      <int> 3, 3, 3, 4, 3, 2, 4, 4, 4, 3, 4, 3, 3, 3, 3, 3, 4, 4, 3,…\n$ salary        <fct> low, medium, medium, high, high, medium, high, medium, l…\n$ tenure        <dbl> 5, 6, 6, 8, 5, 5, 5, 7, 6, 6, 5, 5, 6, 5, 6, 6, 6, 5, 6,…\n$ satisfaction  <dbl> 0.6267590, 0.4436790, 0.4468232, 0.4401387, 0.5776074, 0…\n$ bonus         <fct> 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,…\n$ avg_hrs_month <dbl> 180.8661, 182.7081, 184.4161, 188.7075, 179.8211, 178.84…\n$ left          <fct> no, no, no, no, no, no, no, no, no, no, no, no, no, no, …\n$ left.Numeric  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n\n\n\nTurnover\nNumber of employees that left the company:\nThe overall attrition rate in the company is 29.2%, which means that 2,784 of 9,540 employees have left the company over the past 24 months.\n\n\nShow the code\nempl_turnover_left <- single_prop(empl_turnover, var = \"left\", lev = \"yes\")\nsummary(empl_turnover_left)\n\n\nSingle proportion test (binomial exact)\nData      : empl_turnover \nVariable  : left \nLevel     : yes in left \nConfidence: 0.95 \nNull hyp. : the proportion of yes in left = 0.5 \nAlt. hyp. : the proportion of yes in left not equal to 0.5 \n\n     p    ns     n n_missing    sd    se    me\n 0.292 2,784 9,540         0 0.455 0.005 0.009\n\n   diff    ns p.value  2.5% 97.5%    \n -0.208 2,784  < .001 0.283 0.301 ***\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nAre the employees leaving the different departments at the same rate?\n\nThe data shows that the IT department has the highest employee turnover rate, followed by logistics and retail. Finance has the lowest rate.\n\n\n\nShow the code\nempl_turnover_prop <- empl_turnover %>% \n  tabyl(department, left) %>%\n  adorn_percentages(\"row\") %>%\n  mutate(Perc_empl_left = paste0(round(yes * 100),\"%\"))\n\nkable(empl_turnover_prop,  caption = \"Department vs Attrition\")\n\n\n\nDepartment vs Attrition\n\n\ndepartment\nno\nyes\nPerc_empl_left\n\n\n\n\nadmin\n0.7186761\n0.2813239\n28%\n\n\nengineering\n0.7117414\n0.2882586\n29%\n\n\nfinance\n0.7313433\n0.2686567\n27%\n\n\nIT\n0.6910112\n0.3089888\n31%\n\n\nlogistics\n0.6916667\n0.3083333\n31%\n\n\nmarketing\n0.6970075\n0.3029925\n30%\n\n\noperations\n0.7135348\n0.2864652\n29%\n\n\nretail\n0.6943543\n0.3056457\n31%\n\n\nsales\n0.7148168\n0.2851832\n29%\n\n\nsupport\n0.7115646\n0.2884354\n29%\n\n\n\n\n\n\n\nShow the code\nempl_turnover$reordept <-reorder(empl_turnover$department, empl_turnover$left, \n                                 FUN=function(x) mean(as.numeric(x)))\n\n\nplot_depart <- empl_turnover %>%\nggplot(aes(x = reordept, fill = left)) +\ngeom_bar(position = \"fill\")+\nscale_fill_manual(values=c(\"gray\", \"#2166AC\"))+\nlabs(title = \"Turnover Rate by Department\",\n      y= \" \",\n      x= \" \") +\ncoord_flip() +\n ggpubr::theme_pubclean()+\ntheme(\n    plot.title = element_text(size =9, face = \"bold\", hjust = 0.55),\n    legend.position=\"bottom\")\n\nplot_depart\n\n\n\n\n\n\n\nAttrition vs Years at the company\nThe majority of employees that left the organization, had been working for the company between 5 to 8 years, and the proportion steadily declined.\nWhat does it mean for the organization? Well,\n\n\nShow the code\n### Tenure vs Turnover\n\n\nempl_turnover %>%\ngroup_by(tenure, left)%>%\nggplot(aes(x = tenure, fill = left)) +\ngeom_histogram(bins = 30L) +\n\nscale_fill_manual(values=c(\"gray\", \"#2166AC\"))+\n\n ggpubr::theme_pubclean()+\n\n\n  labs( x= \"Years at the Company\",\n        y= \"Number of Employees\",\n        title = \"Attrition vs Number of Years Working at the Company\")+\n\ntheme(plot.title = element_text(size =12, face = \"bold\", hjust = 0.45),\nlegend.position=\"bottom\")\n\n\n\n\n\n\n\nDo the number of projects employees are involved in and the number of hours per month worked matter in their retention?\nYes, there is a high attrition rate in employees that: - Are involved in less than three projects - Tend to work ~184 hours per month (assuming a five days work week- 8 hours each)\n\n\nShow the code\n## Projects vs Turnover\n\nprojects_turnover <- compare_props(\n  empl_turnover, \n  var1 = \"projects\", \n  var2 = \"left\", \n  levs = \"yes\")\n\nplot_proj <- plot(projects_turnover, plots = \"bar\", custom = TRUE)+ \n             labs(title = \"Attrition vs Number of Projects\",\n                      y = \" Percentage of Employees that Left\",\n                      x = \"Number of Projects Involved in\") +\n              scale_fill_discrete_diverging(\"Blue-Red\")+\n              ggpubr::theme_pubclean()+\n              theme( plot.title = element_text(size =10, \n                                               face = \"bold\", \n                                               hjust = 0.55),\n                     legend.position=\"none\")\n\n## Avg hours vs Turnover\n\nplot_avg_hrs_month <- empl_turnover %>%\n    ggplot() +\n    aes() +\n    geom_histogram(aes(y = ..density.., x = avg_hrs_month, fill = left), bins=30, )+\n    \n    facet_wrap(~ left) +   \n    scale_y_continuous(labels = scales::percent)+\n\n             labs(title = \"Attrition vs Avg Hours Worked\",\n                      y = \"Employment Status (Left)\",\n                      x = \"Number of hours worked\") +\n              scale_fill_manual(values=c(\"gray\", \"#2166AC\"))+ \n              ggpubr::theme_pubclean()+\n              theme( plot.title = element_text(size =10, face = \"bold\", hjust = 0.55),\n                     legend.position=\"none\")\n\n\n\n\n\n\n\n\n\nAttrition vs Promotion, Bonus and Salary\nMost employees are in the medium salary tier, with the rest evenly split between low and high salaries. However, this variable is no significant impact on the turnover status of the employee. Likewise, whether or not an employee received a bonus is not statistically significant on the decision to stay or leave the company.\nThe promotion variable shows a higher proportion of employees had stayed with the organization if they had received a promotion.\n\n\n\n\n\n\n\n\n\n\nEmployee Satisfaction and Review score\n\nEmployees tend to have lower satisfaction ratings as performance scores increase across employees. As the chart below shows, this feature is more appreciable for employees who have left the company in the last 24 months.\n\n\n\nShow the code\nplot_rev_sat_left<- empl_turnover %>% \n  ggplot(aes(x=review,y= satisfaction, color=left)) +\n  geom_point(alpha=0.16) + \n  geom_smooth(method=lm,se=FALSE)+\n  facet_wrap(~department, ncol=4)+\n   ggpubr::theme_pubclean()+\n   labs (x = \"Review\", \n         y = \"Satisfaction Level\",\n         title= \"\") +\n  theme(\n          strip.background= element_rect(fill= \"white\", linetype = \"blank\"),\n          strip.text = element_text(color= \"black\", face= \"bold\"),\n          strip.text.x = element_text(face = \"bold\", size= 10),\n          \n          plot.title = element_text(size =9, face = \"bold\", hjust = 0.55),\n          plot.title.position = \"plot\")+\n          scale_color_manual(values=c(\"gray\", \"#2166AC\"))\n\n\n\nplot_rev_sat_left"
  },
  {
    "objectID": "posts/Regression/Analyzing Employee Turnover.html#the-model",
    "href": "posts/Regression/Analyzing Employee Turnover.html#the-model",
    "title": "Analyzing Employee Turnover",
    "section": "4. The Model",
    "text": "4. The Model\n\nA Scaled Coefficient Plot\nThe graph below shows that not all the predictors are important in deciding to leave the company. Review, satisfaction, promoted and avg_hrs_month, by conventional standards, have a very low probability of no relationship/zero slopes.\n\n\nShow the code\nempl_turnover %>%\n    mutate(review = scale(review), satisfaction = scale(satisfaction), tenure = scale(tenure),projects = scale(projects), avg_hrs_month = scale(avg_hrs_month)) %>%\n  \n    glm(left ~ department+ review+ satisfaction+ avg_hrs_month+ promoted+ tenure+ promoted+ projects+ salary+ bonus,\n        family = binomial(link = \"probit\"), data = .) %>%\n    plot_summs(., inner_ci_level = 0.95)\n\n\n\n\n\n\n\nLogistic Regression\nFor my model I will use the following variables: promoted, review, projects, satisfaction, and average hours worked. This decision was made based on an stepwise regression model (using both forward selection and backward elimination) where all the variables were included and the once with low colinearity were eliminated.\n\n\nShow the code\nempl_tur<- empl_turnover %>% dplyr:::select(c(-reordept, -left.Numeric))\n\n\n\n\nShow the code\nfull.model <- glm(left~ department+ promoted+ review+ projects+\nsalary+ tenure+ satisfaction+ bonus+ avg_hrs_month, \ndata = empl_tur, family = binomial)\n\nsummary(full.model)\n\n\n\nCall:\nglm(formula = left ~ department + promoted + review + projects + \n    salary + tenure + satisfaction + bonus + avg_hrs_month, family = binomial, \n    data = empl_tur)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.4381  -0.8205  -0.6034   1.0706   2.7779  \n\nCoefficients:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)           -21.493059   4.739307  -4.535 5.76e-06 ***\ndepartmentengineering   0.010344   0.130062   0.080 0.936608    \ndepartmentfinance      -0.070328   0.165088  -0.426 0.670107    \ndepartmentIT            0.121550   0.168377   0.722 0.470360    \ndepartmentlogistics     0.098104   0.167795   0.585 0.558773    \ndepartmentmarketing     0.043406   0.141465   0.307 0.758972    \ndepartmentoperations   -0.028534   0.129996  -0.219 0.826263    \ndepartmentretail        0.114473   0.129461   0.884 0.376575    \ndepartmentsales        -0.005853   0.127297  -0.046 0.963328    \ndepartmentsupport       0.024313   0.144010   0.169 0.865934    \npromotedYes            -0.558972   0.156892  -3.563 0.000367 ***\nreview                 11.160858   0.363223  30.727  < 2e-16 ***\nprojects               -0.067532   0.041581  -1.624 0.104350    \nsalarymedium            0.075272   0.069816   1.078 0.280970    \nsalaryhigh              0.018895   0.087327   0.216 0.828700    \ntenure                 -0.011131   0.082660  -0.135 0.892880    \nsatisfaction            2.457897   0.186556  13.175  < 2e-16 ***\nbonusYes               -0.057958   0.059113  -0.980 0.326853    \navg_hrs_month           0.066040   0.028298   2.334 0.019609 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 11520  on 9539  degrees of freedom\nResidual deviance: 10337  on 9521  degrees of freedom\nAIC: 10375\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\nLet’s split the data\n\n\nShow the code\nset.seed(123)\ndata_split <- initial_split(empl_tur, prop = 3/4)\n\ntrain.data <- training(data_split)\n\ntest.data  <- testing(data_split)\n\n\n\n\nComputing stepwise logistique regression\n\n\nShow the code\n# Fit the model\n\nmodel <- glm(left ~ department+ promoted+ review+ projects+\nsalary+ tenure+ satisfaction+ bonus+ avg_hrs_month,\ndata = train.data, family = binomial) %>%\n  stepAIC(trace = FALSE)\n\n# Summarize the final selected model\nsummary(model)\n\n\n\nCall:\nglm(formula = left ~ promoted + review + satisfaction + bonus + \n    avg_hrs_month, family = binomial, data = train.data)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.0471  -0.8148  -0.5930   1.0487   2.7958  \n\nCoefficients:\n                Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   -20.765742   1.441891 -14.402  < 2e-16 ***\npromotedYes    -0.586594   0.178620  -3.284  0.00102 ** \nreview         11.655310   0.428243  27.217  < 2e-16 ***\nsatisfaction    2.680873   0.219774  12.198  < 2e-16 ***\nbonusYes       -0.131276   0.069554  -1.887  0.05911 .  \navg_hrs_month   0.058488   0.006937   8.431  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 8595.3  on 7154  degrees of freedom\nResidual deviance: 7660.6  on 7149  degrees of freedom\nAIC: 7672.6\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\nPerform stepwise variable selection\nSelect the most contributive variables:\n\n\nShow the code\nmodel2 <- glm(formula = left ~ promoted + review + satisfaction + bonus + tenure +  avg_hrs_month, family = binomial, data = train.data)\n\ncoef(model2)\n\n\n  (Intercept)   promotedYes        review  satisfaction      bonusYes \n -24.92708321   -0.58724188   11.66591046    2.67842602   -0.13178813 \n       tenure avg_hrs_month \n  -0.07543137    0.08367092 \n\n\nShow the code\nmodel_diagnostics2 <- LogisticDx::gof(model2, plotROC = TRUE)\n\n\n\n\n\nThe accuracy of this model is 74%, that is - the model about 74% of the time can correctly classify whether an individual will leave or stay.\nFurther work can explore other classification models (such as decision trees) to improve performance for determining factors influencing an employee’s reason to leave. Improving prediction response can help identify the most at-risk staff."
  },
  {
    "objectID": "posts/Time-Series/TimeSeries.html",
    "href": "posts/Time-Series/TimeSeries.html",
    "title": "Time Series Project",
    "section": "",
    "text": "Show the code\nlibrary(tidyverse)\nlibrary(lubridate); library(tsibble)\nlibrary(readxl)\nlibrary(fpp3)"
  },
  {
    "objectID": "posts/Time-Series/TimeSeries.html#step-1-problem-definition",
    "href": "posts/Time-Series/TimeSeries.html#step-1-problem-definition",
    "title": "Time Series Project",
    "section": "Step 1: Problem Definition",
    "text": "Step 1: Problem Definition\nIn this project, I will perform a time series analysis using Zillow’s historical median home prices for the US from March 2015 to October 2022. The project aims to provide information on renting costs in Orlando- FL, Portland- OR, and Houston- TX, and find the month that offers the lowest price to move in."
  },
  {
    "objectID": "posts/Time-Series/TimeSeries.html#step-2-gathering-information",
    "href": "posts/Time-Series/TimeSeries.html#step-2-gathering-information",
    "title": "Time Series Project",
    "section": "Step 2: Gathering Information",
    "text": "Step 2: Gathering Information\nYou can find this free dataset on the Zillow website: https://www.zillow.com/research/data/#other-metrics\n\n\nShow the code\nraw_city <- read.csv(\"C:/Users/karol/Desktop/Portfolio/City_zori_sm_month.csv\")\n\n\n\nRegionID: This is unique Id for the Regions\nSizeRank: This is the ranking done based on the size of the region\nRegionName: This field contains the name of the city.\nRegionType: Type of region.\nStateName: State\nState: This column provide the specific City Name of Housing Data\nMetro: This provide the name of the metro city around that region\nCounty: Name This is the county name for that region\nMonths: Column These columns contains the prices of region for every month since 2015- 2022"
  },
  {
    "objectID": "posts/Time-Series/TimeSeries.html#step-3-preliminary-exploratory-analysis.",
    "href": "posts/Time-Series/TimeSeries.html#step-3-preliminary-exploratory-analysis.",
    "title": "Time Series Project",
    "section": "Step 3: Preliminary (exploratory) analysis.",
    "text": "Step 3: Preliminary (exploratory) analysis.\n\n\nShow the code\nstr(raw_city[,c(1:11)])\n\n\n'data.frame':   3500 obs. of  11 variables:\n $ RegionID  : int  6181 12447 39051 17426 6915 40326 13271 18959 54296 38128 ...\n $ SizeRank  : int  0 1 2 3 4 5 6 7 8 9 ...\n $ RegionName: chr  \"New York\" \"Los Angeles\" \"Houston\" \"Chicago\" ...\n $ RegionType: chr  \"city\" \"city\" \"city\" \"city\" ...\n $ StateName : chr  \"NY\" \"CA\" \"TX\" \"IL\" ...\n $ State     : chr  \"NY\" \"CA\" \"TX\" \"IL\" ...\n $ Metro     : chr  \"New York-Newark-Jersey City, NY-NJ-PA\" \"Los Angeles-Long Beach-Anaheim, CA\" \"Houston-The Woodlands-Sugar Land, TX\" \"Chicago-Naperville-Elgin, IL-IN-WI\" ...\n $ CountyName: chr  \"Queens County\" \"Los Angeles County\" \"Harris County\" \"Cook County\" ...\n $ X3.31.2015: num  2730 2004 1285 1555 1019 ...\n $ X4.30.2015: num  2755 2011 1293 1572 1029 ...\n $ X5.31.2015: num  2780 2033 1304 1587 1040 ...\n\n\nWe have to make this dataset tidy. Tidy Data is a way of structuring data so that it can be easily understood by people and analyzed by machines.\nI need to remove the X at the beginning of the dates (X3.31.2015,…)\n\n\nShow the code\nnames(raw_city) <- sub(\"^X\", \"\", names(raw_city))\nstr(raw_city[,c(1:10)],10)\n\n\n'data.frame':   3500 obs. of  10 variables:\n $ RegionID  : int  6181 12447 39051 17426 6915 40326 13271 18959 54296 38128 ...\n $ SizeRank  : int  0 1 2 3 4 5 6 7 8 9 ...\n $ RegionName: chr  \"New York\" \"Los Angeles\" \"Houston\" \"Chicago\" ...\n $ RegionType: chr  \"city\" \"city\" \"city\" \"city\" ...\n $ StateName : chr  \"NY\" \"CA\" \"TX\" \"IL\" ...\n $ State     : chr  \"NY\" \"CA\" \"TX\" \"IL\" ...\n $ Metro     : chr  \"New York-Newark-Jersey City, NY-NJ-PA\" \"Los Angeles-Long Beach-Anaheim, CA\" \"Houston-The Woodlands-Sugar Land, TX\" \"Chicago-Naperville-Elgin, IL-IN-WI\" ...\n $ CountyName: chr  \"Queens County\" \"Los Angeles County\" \"Harris County\" \"Cook County\" ...\n $ 3.31.2015 : num  2730 2004 1285 1555 1019 ...\n $ 4.30.2015 : num  2755 2011 1293 1572 1029 ...\n\n\nNow, I will create a new column called Price, where the values from the dates column will merge into it.\n\n\nShow the code\nrent_city <- raw_city %>% \n  pivot_longer(-c(RegionID,SizeRank,RegionName,RegionType,StateName,State,Metro,CountyName),\n    names_to = \"Monthly\",\n    values_to = \"Price\"\n  ) \nstr(rent_city)\n\n\ntibble [318,500 × 10] (S3: tbl_df/tbl/data.frame)\n $ RegionID  : int [1:318500] 6181 6181 6181 6181 6181 6181 6181 6181 6181 6181 ...\n $ SizeRank  : int [1:318500] 0 0 0 0 0 0 0 0 0 0 ...\n $ RegionName: chr [1:318500] \"New York\" \"New York\" \"New York\" \"New York\" ...\n $ RegionType: chr [1:318500] \"city\" \"city\" \"city\" \"city\" ...\n $ StateName : chr [1:318500] \"NY\" \"NY\" \"NY\" \"NY\" ...\n $ State     : chr [1:318500] \"NY\" \"NY\" \"NY\" \"NY\" ...\n $ Metro     : chr [1:318500] \"New York-Newark-Jersey City, NY-NJ-PA\" \"New York-Newark-Jersey City, NY-NJ-PA\" \"New York-Newark-Jersey City, NY-NJ-PA\" \"New York-Newark-Jersey City, NY-NJ-PA\" ...\n $ CountyName: chr [1:318500] \"Queens County\" \"Queens County\" \"Queens County\" \"Queens County\" ...\n $ Monthly   : chr [1:318500] \"3.31.2015\" \"4.30.2015\" \"5.31.2015\" \"6.30.2015\" ...\n $ Price     : num [1:318500] 2730 2755 2780 2805 2821 ...\n\n\n\n\nShow the code\n#Converting the Date from factor to character\n\nrent_clean <- rent_city %>%\n            mutate(Monthly_parsed = as.Date(Monthly,\"%m.%d.%Y\"))\n\n\nrent_clean[[\"Monthly\"]]<- as.character(rent_clean$Monthly)\n\nrent_city[[\"Monthly\"]]<- as.character(rent_city$Monthly)\nsummary(rent_city)\n\n\n    RegionID         SizeRank        RegionName         RegionType       \n Min.   :  3310   Min.   :    0.0   Length:318500      Length:318500     \n 1st Qu.: 16840   1st Qu.:  886.8   Class :character   Class :character  \n Median : 31552   Median : 1902.5   Mode  :character   Mode  :character  \n Mean   : 63080   Mean   : 2637.9                                        \n 3rd Qu.: 46147   3rd Qu.: 3441.2                                        \n Max.   :840556   Max.   :28107.0                                        \n                                                                         \n  StateName            State              Metro            CountyName       \n Length:318500      Length:318500      Length:318500      Length:318500     \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n   Monthly              Price         \n Length:318500      Min.   :     0.0  \n Class :character   1st Qu.:   912.1  \n Mode  :character   Median :  1273.5  \n                    Mean   :  1392.0  \n                    3rd Qu.:  1694.8  \n                    Max.   :112760.4  \n                    NA's   :28270     \n\n\nWe see some missing values in the Price variable, but before I deal with those values, I will filter my data to the cities that I am interested the most: Houston, Orlando, and Portland.\n\n\nShow the code\npreferred_cities <- rent_clean %>%\n  dplyr:::filter(RegionName %in% c(\"Houston\", \"Orlando\", \"Portland\")) %>%\n  dplyr:::filter(RegionID %in% c(\"13121\", \"13373\", \"39051\"))\n\nsummary(preferred_cities)\n\n\n    RegionID        SizeRank      RegionName         RegionType       \n Min.   :13121   Min.   : 2.00   Length:273         Length:273        \n 1st Qu.:13121   1st Qu.: 2.00   Class :character   Class :character  \n Median :13373   Median :20.00   Mode  :character   Mode  :character  \n Mean   :21848   Mean   :14.67                                        \n 3rd Qu.:39051   3rd Qu.:22.00                                        \n Max.   :39051   Max.   :22.00                                        \n  StateName            State              Metro            CountyName       \n Length:273         Length:273         Length:273         Length:273        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n   Monthly              Price      Monthly_parsed      \n Length:273         Min.   :1195   Min.   :2015-03-31  \n Class :character   1st Qu.:1362   1st Qu.:2017-01-31  \n Mode  :character   Median :1473   Median :2018-12-31  \n                    Mean   :1490   Mean   :2018-12-30  \n                    3rd Qu.:1578   3rd Qu.:2020-11-30  \n                    Max.   :2088   Max.   :2022-09-30  \n\n\n\nAfter filtering the data, we don’t have any missing values\nWe see that the date goes from March 31, 2015, to September 30, 2022, with a monthly calculation of the rental value.\nThe monthly rent cost goes from 1,172 to 2,153 dollars\n\n\nCoerce to a tsibble with as_tsibble()- Three Cities\nA time series can be recorded as a tsibble object in R. tsibble objects extend tidy data frames (tibble objects) by introducing temporal structure, and to do it, we need to declare key and index. In this case, the Monthly_parsed containing the data-time is the index and the RegionID is the key. Other columns can be considered as measured variables.\n\n\nShow the code\ntsb_pref_cities <- preferred_cities %>%\n                   select(RegionName,RegionID, Monthly_parsed, Price)\n\ntsb_pref_cities <-tsb_pref_cities%>%\n  as_tsibble(key= RegionName, index= Monthly_parsed)%>%\n                   index_by(year_month = ~ yearmonth(.))\n\ntsibble_df <-tsb_pref_cities%>%\n  select(-RegionID)%>%\n  as_tsibble(key= RegionName, index= year_month)\n\n\nTo visualize the data, I could usee the autoplot() command, but I rather to create my graph with ggplot.\n\n\nShow the code\nplot_cities <- tsibble_df %>%\n  ggplot(aes(x= year_month, y= Price, color= RegionName)) +\n  geom_line(size=1)+\n   \n    labs(y=\"Rent Price in US Dollars\", \n       x= \"Year\",\n       title=\"Rent Cost in Portland, Orlando & Houston, 2015-2022\",\n       caption = \"data:https://www.zillow.com/research/data\")+\n  scale_colour_hue(name= \" \")+\n  scale_y_continuous(labels=scales::dollar_format())\n\nplot_cities\n\n\n\n\n\n\n\nSeasonal Plots\n\n\nShow the code\npdx <- tsibble_df %>%\n  filter(RegionName == \"Portland\")\n\npdx%>%\ngg_season(Price, labels = \"both\")+\n  labs(x= \"\",\n       y= \"\",\n       title=\"Portland\")+\n  scale_y_continuous(labels=scales::dollar_format())\n\n\n\n\n\n\n\nShow the code\nhst <- tsibble_df %>%\n  filter(RegionName == \"Houston\")\n\n\nhst%>%\ngg_season(Price, labels = \"both\")+\n  labs(x= \"\",\n       y= \"\",\n       title=\"Houston\")+\n  scale_y_continuous(labels=scales::dollar_format())\n\n\n\n\n\n\n\nShow the code\norl <- tsibble_df %>%\n  filter(RegionName == \"Orlando\")\n\n\norl%>%\ngg_season(Price, labels = \"both\")+\n  labs(x= \"\",\n       y= \"\",\n       title=\"Orlando\")+\n  scale_y_continuous(labels=scales::dollar_format())\n\n\n\n\n\n\n\nSubseries\n\n\nShow the code\npdx%>%\ngg_subseries(Price)+\n  labs(y= \"Rent Price\",\n       x= \"Year\")+\n  scale_y_continuous(labels=scales::dollar_format())+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n\n\n\n\nShow the code\nhst %>%\ngg_subseries(Price)+\n  labs(y= \"Rent Price\",\n       x= \"Year\")+\n  scale_y_continuous(labels=scales::dollar_format())+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n\n\n\n\nShow the code\norl%>%\ngg_subseries(Price)+\n  labs(y= \"Rent Price\",\n       x= \"Year\")+\n  scale_y_continuous(labels=scales::dollar_format())+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))"
  },
  {
    "objectID": "posts/Time-Series/TimeSeries.html#step-4-choosing-and-fitting-models",
    "href": "posts/Time-Series/TimeSeries.html#step-4-choosing-and-fitting-models",
    "title": "Time Series Project",
    "section": "Step 4: Choosing and fitting models",
    "text": "Step 4: Choosing and fitting models"
  },
  {
    "objectID": "posts/Time-Series/TimeSeries.html#step-5-using-and-evaluating-a-forecasting-model",
    "href": "posts/Time-Series/TimeSeries.html#step-5-using-and-evaluating-a-forecasting-model",
    "title": "Time Series Project",
    "section": "Step 5: Using and evaluating a forecasting model",
    "text": "Step 5: Using and evaluating a forecasting model"
  }
]