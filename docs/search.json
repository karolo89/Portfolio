[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Portfolio",
    "section": "",
    "text": "Dec 4, 2022\n\n\nKarol Orozco\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\nKarol Orozco\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/House Prices in Porltand/Portland Prices- Regression.html",
    "href": "posts/House Prices in Porltand/Portland Prices- Regression.html",
    "title": "House Prices in Porltand, OR",
    "section": "",
    "text": "The goal is to build a classification model to predict the type of median housing prices in Portland, OR and its metropolitan area."
  },
  {
    "objectID": "posts/House Prices in Porltand/Portland Prices- Regression.html#get-the-data",
    "href": "posts/House Prices in Porltand/Portland Prices- Regression.html#get-the-data",
    "title": "House Prices in Porltand, OR",
    "section": "Get the Data",
    "text": "Get the Data\n\n\nShow the code\nraw_pdx <- read.csv(\"C:/Users/karol/Desktop/PORTLAND HOUSE.csv\", stringsAsFactors=TRUE)"
  },
  {
    "objectID": "posts/House Prices in Porltand/Portland Prices- Regression.html#prepare-the-data",
    "href": "posts/House Prices in Porltand/Portland Prices- Regression.html#prepare-the-data",
    "title": "House Prices in Porltand, OR",
    "section": "Prepare the Data",
    "text": "Prepare the Data\nThis data has 25731 obs. of 32 variables\n\n\nShow the code\n## raw_pdx <- raw_pdx%>%select(-id)\n\nhead(raw_pdx)\n\n\n  id yearBuilt     City latitude longitude zipcode bathrooms bedrooms\n1  1      2007 Fairview 45.54357 -122.4418   97024         3        3\n2  2      2001 Fairview 45.54758 -122.4532   97024         3        3\n3  3      1982  Gresham 45.48823 -122.4444   97080         3        4\n4  4      1953 Portland 45.52663 -122.4641   97230         1        3\n5  5      1967  Gresham 45.51124 -122.4315   97030         3        6\n6  6      1967  Gresham 45.48799 -122.4162   97080         2        3\n  DateListed  DateSold daysOnZillow      homeType lastSoldPrice livingArea\n1  4/26/2021 5/21/2021           25     TOWNHOUSE        315400       1806\n2   3/1/2021 4/23/2021           53 SINGLE_FAMILY        400000       1518\n3  5/24/2021  6/4/2021           11 SINGLE_FAMILY        512000       2724\n4  5/24/2021  6/4/2021           11 SINGLE_FAMILY        348000       1217\n5  5/18/2021  6/1/2021           14     APARTMENT        510000       2400\n6  5/18/2021  6/1/2021           14 SINGLE_FAMILY        404200       1150\n  lotSize  price priceHistory.1.price propertyTaxRate hasCooling hasFireplace\n1    1555 315400               212000            1.12      FALSE         TRUE\n2    3484 400000               375000            1.12       TRUE         TRUE\n3    9583 512000               479000            1.12       TRUE         TRUE\n4   13939 348000               339500            1.12         NA         TRUE\n5    8545 510000               252450            1.12       TRUE           NA\n6    7000 404200               204500            1.12      FALSE         TRUE\n  hasGarage hasHeating hasView ElementarySchooldistance ElementarySchools\n1     FALSE       TRUE   FALSE                      0.4        Elementary\n2     FALSE       TRUE    TRUE                      1.2        Elementary\n3     FALSE       TRUE    TRUE                      0.8        Elementary\n4     FALSE       TRUE   FALSE                      0.8        Elementary\n5     FALSE       TRUE   FALSE                      0.3        Elementary\n6     FALSE       TRUE   FALSE                      0.4        Elementary\n  ElementarySchoolrating MiddleSchooldistance schoolsMiddlelevel\n1                      5                  1.1             Middle\n2                      5                  1.0             Middle\n3                      5                  1.7             Middle\n4                      2                  0.7             Middle\n5                      2                  0.9             Middle\n6                      2                  0.4             Middle\n  MiddleSchoolsrating HighSchooldistance HighSchoollevel HighSchoolRating\n1                   2                2.6            High                3\n2                   2                3.4            High                3\n3                   6                1.4            High                3\n4                   2                3.8            High                3\n5                   6                0.3            High                3\n6                   6                1.4            High                3\n\n\n\n\nShow the code\n# convert variables\n\nraw_pdx <-  raw_pdx %>% \n  \n  mutate(\n    \n    yearBuilt = as.numeric(yearBuilt),\n    bathrooms = as.numeric(bathrooms),\n    bedrooms = as.numeric(bedrooms),\n    daysOnZillow = as.numeric(daysOnZillow),\n    lastSoldPrice = as.numeric(lastSoldPrice ),\n    livingArea = as.numeric(livingArea),\n    lotSize= as.numeric(lotSize),\n    price = as.numeric(price),\n    priceHistory.1.price= as.numeric(priceHistory.1.price),\n    \n    \n    ElementarySchoolrating = as.factor(ElementarySchoolrating),\n    MiddleSchoolsrating = as.factor(MiddleSchoolsrating),\n    HighSchoolRating= as.factor(HighSchoolRating),\n    zipcode = as.factor(zipcode)\n\n    \n  )\n\n\n\nMissing data\n\n\nShow the code\nis.na(raw_pdx) %>% colSums()\n\n\n                      id                yearBuilt                     City \n                       0                      546                        0 \n                latitude                longitude                  zipcode \n                      13                       13                        0 \n               bathrooms                 bedrooms               DateListed \n                     484                      770                        0 \n                DateSold             daysOnZillow                 homeType \n                       0                        6                        0 \n           lastSoldPrice               livingArea                  lotSize \n                       0                      465                     2890 \n                   price     priceHistory.1.price          propertyTaxRate \n                       0                     1419                       11 \n              hasCooling             hasFireplace                hasGarage \n                    4496                     4624                        0 \n              hasHeating                  hasView ElementarySchooldistance \n                       1                        0                       25 \n       ElementarySchools   ElementarySchoolrating     MiddleSchooldistance \n                       0                       25                       36 \n      schoolsMiddlelevel      MiddleSchoolsrating       HighSchooldistance \n                       0                       36                     2242 \n         HighSchoollevel         HighSchoolRating \n                       0                     2242 \n\n\n\n\nShow the code\nclean_data <- raw_pdx %>%\n  filter(!is.na(yearBuilt))%>%\n  filter(!is.na(longitude))%>%\n  filter(!is.na(bedrooms))%>%\n  filter(!is.na(daysOnZillow))%>%\n  filter(!is.na(livingArea))%>%\n  filter(!is.na(priceHistory.1.price))%>%\n  filter(!is.na(hasFireplace))%>%\n  filter(!is.na(latitude))%>%\n  filter(!is.na(hasHeating))%>%\n  filter(!is.na(hasCooling))%>%\n  filter(!is.na(bathrooms))%>%\n  filter(!is.na(lotSize))%>%\n  filter(!is.na(propertyTaxRate))%>%\n  filter(!is.na(ElementarySchooldistance))%>%\n  filter(!is.na(MiddleSchooldistance))%>%\n  filter(!is.na(HighSchooldistance))%>%\n  filter(!is.na(ElementarySchoolrating))%>%\n  filter(!is.na(MiddleSchoolsrating))%>%\n  filter(!is.na(HighSchoolRating))\n\n\n\n\nShow the code\nsummary(clean_data)\n\n\n       id          yearBuilt             City         latitude    \n Min.   :    1   Min.   :   0   Portland   :5232   Min.   :45.26  \n 1st Qu.: 6207   1st Qu.:1965   Beaverton  :1456   1st Qu.:45.42  \n Median :15156   Median :1989   Hillsboro  :1194   Median :45.47  \n Mean   :13622   Mean   :1981   Lake Oswego: 942   Mean   :45.47  \n 3rd Qu.:20440   3rd Qu.:2003   Tigard     : 913   3rd Qu.:45.52  \n Max.   :25730   Max.   :2021   Gresham    : 845   Max.   :45.62  \n                                (Other)    :3906                  \n   longitude         zipcode        bathrooms        bedrooms     \n Min.   :-123.1   97229  :  834   Min.   : 0.00   Min.   : 0.000  \n 1st Qu.:-122.8   97045  :  713   1st Qu.: 2.00   1st Qu.: 3.000  \n Median :-122.7   97007  :  706   Median : 3.00   Median : 3.000  \n Mean   :-122.7   97086  :  632   Mean   : 2.78   Mean   : 3.568  \n 3rd Qu.:-122.6   97123  :  599   3rd Qu.: 3.00   3rd Qu.: 4.000  \n Max.   :-122.3   97068  :  573   Max.   :10.00   Max.   :10.000  \n                  (Other):10431                                   \n     DateListed          DateSold      daysOnZillow              homeType    \n 8/9/2019 :   71   5/28/2021 :  159   Min.   :  1   APARTMENT        :   38  \n 6/4/2021 :   66   6/30/2021 :  142   1st Qu.: 80   CONDO            :  136  \n 3/30/2021:   65   10/30/2020:  137   Median :192   HOME_TYPE_UNKNOWN:    2  \n 8/6/2019 :   64   7/31/2020 :  128   Mean   :187   SINGLE_FAMILY    :13659  \n 8/19/2019:   62   4/30/2021 :  127   3rd Qu.:294   TOWNHOUSE        :  653  \n 8/23/2019:   60   9/30/2020 :  122   Max.   :422                            \n (Other)  :14100   (Other)   :13673                                          \n lastSoldPrice       livingArea       lotSize             price        \n Min.   :    443   Min.   :  416   Min.   :       0   Min.   :    500  \n 1st Qu.: 450000   1st Qu.: 1664   1st Qu.:    4791   1st Qu.: 450000  \n Median : 551000   Median : 2206   Median :    7405   Median : 551000  \n Mean   : 634458   Mean   : 2399   Mean   :   17065   Mean   : 634827  \n 3rd Qu.: 710000   3rd Qu.: 2892   3rd Qu.:   10018   3rd Qu.: 710000  \n Max.   :6300000   Max.   :14014   Max.   :18992160   Max.   :6300000  \n                                                                       \n priceHistory.1.price propertyTaxRate hasCooling      hasFireplace   \n Min.   :    895      Min.   :1.010   Mode :logical   Mode :logical  \n 1st Qu.: 415000      1st Qu.:1.080   FALSE:807       FALSE:645      \n Median : 525000      Median :1.120   TRUE :13681     TRUE :13843    \n Mean   : 594080      Mean   :1.113                                  \n 3rd Qu.: 679992      3rd Qu.:1.130                                  \n Max.   :6888000      Max.   :1.130                                  \n                                                                     \n hasGarage       hasHeating       hasView        ElementarySchooldistance\n Mode :logical   Mode :logical   Mode :logical   Min.   :0.0000          \n FALSE:14150     FALSE:24        FALSE:8574      1st Qu.:0.4000          \n TRUE :338       TRUE :14464     TRUE :5914      Median :0.6000          \n                                                 Mean   :0.8057          \n                                                 3rd Qu.:1.0000          \n                                                 Max.   :9.4000          \n                                                                         \n  ElementarySchools ElementarySchoolrating MiddleSchooldistance\n           :    0   7      :2862           Min.   : 0.000      \n Elementary:13077   5      :2359           1st Qu.: 0.800      \n Primary   : 1411   6      :2323           Median : 1.300      \n                    8      :1606           Mean   : 1.546      \n                    3      :1368           3rd Qu.: 2.100      \n                    4      :1332           Max.   :11.900      \n                    (Other):2638                               \n  schoolsMiddlelevel MiddleSchoolsrating HighSchooldistance HighSchoollevel\n           :    0    5      :2347        Min.   : 0.100         :    0     \n Elementary:    3    8      :2262        1st Qu.: 1.000     High:14488     \n High      :    0    3      :2238        Median : 1.700                    \n Middle    :14485    6      :2104        Mean   : 1.911                    \n                     7      :1655        3rd Qu.: 2.500                    \n                     4      :1595        Max.   :10.800                    \n                     (Other):2287                                          \n HighSchoolRating\n 5      :3804    \n 8      :2365    \n 3      :1962    \n 6      :1787    \n 9      :1746    \n 4      :1230    \n (Other):1594    \n\n\n\n\nShow the code\nclean_data <- \n  clean_data %>% \n  mutate(price_category = case_when( \n    price < 551000 ~ \"below\",\n    price >= 551000 ~ \"above\")) %>% \n  mutate(price_category = as.factor(price_category)) \n\n\n\n\nTake a look at the Data\n\n\nShow the code\nlibrary(gt) ## tables\n\n\nWarning: package 'gt' was built under R version 4.2.2\n\n\nShow the code\nclean_data %>% \n  count(price_category, \n        name =\"total\") %>%\n  mutate(percent = total/sum(total)*100,\n         percent = round(percent, 2)) %>%\n gt() %>%\n  tab_header(\n    title = \"Portland, OR and its Metropolitan Area Median House Prices\",\n    subtitle = \"Above and below 551,000$\"\n  ) %>%\n  cols_label(\n    price_category = \"Price\",\n    total = \"Total\",\n    percent = \"Percent\"\n  ) %>% \n  fmt_number(\n    columns = vars(total),\n    suffixing = TRUE\n  ) \n\n\nWarning: Since gt v0.3.0, `columns = vars(...)` has been deprecated.\n• Please use `columns = c(...)` instead.\n\n\nWarning: Since gt v0.3.0, `columns = vars(...)` has been deprecated.\n• Please use `columns = c(...)` instead.\n\n\n\n\n\n\n  \n    \n      Portland, OR and its Metropolitan Area Median House Prices\n    \n    \n      Above and below 551,000$\n    \n  \n  \n    \n      Price\n      Total\n      Percent\n    \n  \n  \n    above\n7.25K\n50.02\n    below\n7.24K\n49.98\n  \n  \n  \n\n\n\n\n\n\nShow the code\nhouses_pdx <-\n  clean_data %>% \n  select( # select our predictors\n    longitude, \n    latitude, \n    price_category,\n    bathrooms, \n    yearBuilt, \n    homeType,\n    bedrooms, \n    livingArea, \n    lotSize,\n    MiddleSchooldistance,\n    ElementarySchooldistance,\n    HighSchooldistance)\n\nglimpse(houses_pdx)\n\n\nRows: 14,488\nColumns: 12\n$ longitude                <dbl> -122.4418, -122.4532, -122.4444, -122.4162, -…\n$ latitude                 <dbl> 45.54357, 45.54758, 45.48823, 45.48799, 45.49…\n$ price_category           <fct> below, below, below, below, below, below, bel…\n$ bathrooms                <dbl> 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, …\n$ yearBuilt                <dbl> 2007, 2001, 1982, 1967, 1978, 2018, 2006, 201…\n$ homeType                 <fct> TOWNHOUSE, SINGLE_FAMILY, SINGLE_FAMILY, SING…\n$ bedrooms                 <dbl> 3, 3, 4, 3, 3, 4, 3, 3, 4, 4, 3, 2, 4, 3, 4, …\n$ livingArea               <dbl> 1806, 1518, 2724, 1150, 2036, 1947, 1548, 220…\n$ lotSize                  <dbl> 1555, 3484, 9583, 7000, 6969, 4791, 5009, 522…\n$ MiddleSchooldistance     <dbl> 1.1, 1.0, 1.7, 0.4, 2.1, 2.5, 0.5, 1.8, 0.3, …\n$ ElementarySchooldistance <dbl> 0.4, 1.2, 0.8, 0.4, 1.0, 0.3, 0.5, 1.0, 0.1, …\n$ HighSchooldistance       <dbl> 2.6, 3.4, 1.4, 1.4, 1.4, 2.2, 1.5, 1.4, 0.9, …\n\n\n\n\nShow the code\npdx_long <- houses_pdx %>% \n  select(-homeType, -yearBuilt, -lotSize)%>%\n    pivot_longer(!price_category, names_to = \"features\", values_to = \"values\")\n\n\n\n\nShow the code\ntheme_set(theme_light())\n\n# Make a box plot for each predictor feature\npdx_long %>% \n  ggplot(mapping = aes(x = price_category, y = values, fill = features)) +\n  geom_boxplot() + \n  facet_wrap(~ features, scales = \"free\", ncol = 4) +\n  scale_color_viridis_d(option = \"plasma\", end = .7) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nShow the code\nlibrary(ggmap)\n\n\nWarning: package 'ggmap' was built under R version 4.2.2\n\n\nℹ Google's Terms of Service: <https://mapsplatform.google.com>\n\n\nℹ Please cite ggmap if you use it! Use `citation(\"ggmap\")` for details.\n\n\nShow the code\nqmplot(x = longitude, \n       y = latitude, \n       data = houses_pdx, \n       geom = \"point\", \n       color = price_category, \n       alpha = 0.4) +\n  scale_alpha(guide = 'none')\n\n\nℹ Using `` zoom = `10` ``\n\n\nℹ Map tiles by Stamen Design, under CC BY 3.0. Data by OpenStreetMap, under ODbL.\n\n\n\n\n\n\n\nData Splitting\n\n\nShow the code\n# Fix the random numbers by setting the seed \n# This enables the analysis to be reproducible \nset.seed(504)\n\n# Put 3/4 of the data into the training set \ndata_split <- initial_split(houses_pdx, \n                           prop = 3/4)\n\n# Create dataframes for the two sets:\ntrain_data <- training(data_split) \ntest_data <- testing(data_split)\n\n\n\n\nValidaton Set\nWe use k-fold crossvalidation to build a set of 5 validation folds with the function vfold_cv. We also use stratified sampling:\n\n\nShow the code\nhouse_folds <-\n vfold_cv(train_data, \n          v = 5, \n          strata = price_category) \n\n\n\n\nData prepropecessing recipe\n\n\nShow the code\npdx_rec <-\n  recipe(price_category ~ .,\n         data = train_data) %>%\n  update_role(longitude, latitude, \n              new_role = \"ID\") %>% \n  \n  step_log(bathrooms, bedrooms, livingArea) %>% ## step_log() will log transform data\n  \n  step_naomit(everything(), skip = TRUE) %>% \n  \n  step_novel(all_nominal(), -all_outcomes()) %>% # converts all nominal variables to factors and takes care of other issues related to categorical variables.\n  \n  step_normalize(all_numeric(), -all_outcomes(), \n                 -longitude, -latitude) %>% # step_normalize() normalizes (center and scales) the numeric variables to have a standard deviation of one and a mean of zero\n  \n  step_dummy(all_nominal(), -all_outcomes()) %>% #converts our factor columns into numeric binary (0 and 1) variables.\n  \n  step_zv(all_numeric(), -all_outcomes()) %>% ## step_zv(): removes any numeric variables that have zero variance.\n  \n  step_corr(all_predictors(), threshold = 0.7, method = \"spearman\") # step_corr(): will remove predictor variables that have large correlations with other predictor variables.\n\n\n\n\nShow the code\nsummary(pdx_rec)\n\n\n# A tibble: 12 × 4\n   variable                 type    role      source  \n   <chr>                    <chr>   <chr>     <chr>   \n 1 longitude                numeric ID        original\n 2 latitude                 numeric ID        original\n 3 bathrooms                numeric predictor original\n 4 yearBuilt                numeric predictor original\n 5 homeType                 nominal predictor original\n 6 bedrooms                 numeric predictor original\n 7 livingArea               numeric predictor original\n 8 lotSize                  numeric predictor original\n 9 MiddleSchooldistance     numeric predictor original\n10 ElementarySchooldistance numeric predictor original\n11 HighSchooldistance       numeric predictor original\n12 price_category           nominal outcome   original"
  },
  {
    "objectID": "posts/House Prices in Porltand/Portland Prices- Regression.html#model-building",
    "href": "posts/House Prices in Porltand/Portland Prices- Regression.html#model-building",
    "title": "House Prices in Porltand, OR",
    "section": "Model building",
    "text": "Model building\n\nSpecify models: Logistic regression\n\n\nShow the code\nlog_spec <- # your model specification\n  logistic_reg() %>%  # model type\n  set_engine(engine = \"glm\") %>%  # model engine\n  set_mode(\"classification\") # model mode\n\n# Show your model specification\nlog_spec\n\n\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\nCreate workflows\n\nBundle recipe and model with workflows\n\n\nShow the code\npdx_wflow <- # new workflow object\n workflow() %>% # use workflow function\n add_recipe(pdx_rec) %>%   # use the new recipe\n add_model(log_spec)   # add your model spec\n\npdx_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n7 Recipe Steps\n\n• step_log()\n• step_naomit()\n• step_novel()\n• step_normalize()\n• step_dummy()\n• step_zv()\n• step_corr()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\n\nLogistic regression\n\n\nShow the code\n# save model coefficients for a fitted model object from a workflow\n\nget_model <- function(x) {\n  pull_workflow_fit(x) %>% tidy()\n}\n\n# same as before with one exception\nlog_res_2 <- \n  pdx_wflow %>% \n  fit_resamples(\n    resamples = house_folds, \n    metrics = metric_set(\n      recall, precision, f_meas, \n      accuracy, kap,\n      roc_auc, sens, spec),\n      control = control_resamples(\n      save_pred = TRUE,\n      extract = get_model) # use extract and our new function\n    ) \n\n\n! Fold5: preprocessor 1/1, model 1/1: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\n\nWarning: More than one set of outcomes were used when tuning. This should never\nhappen. Review how the outcome is specified in your model.\n\n\nShow the code\n## To get the results use:\n\nlog_res_2$.extracts[[1]][[1]]\n\n\nNULL\n\n\nAll of the results can be flattened and collected using:\n\n\nShow the code\nall_coef <- map_dfr(log_res_2$.extracts, ~ .x[[1]][[1]])\nfilter(all_coef, term == \"livingArea\")\n\n\n# A tibble: 4 × 5\n  term       estimate std.error statistic p.value\n  <chr>         <dbl>     <dbl>     <dbl>   <dbl>\n1 livingArea    -2.51    0.0544     -46.1       0\n2 livingArea    -2.41    0.0526     -45.8       0\n3 livingArea    -2.40    0.0524     -45.9       0\n4 livingArea    -2.45    0.0539     -45.6       0\n\n\n\nPerformance metrics\nShow performance for every single fold:\n\n\nShow the code\nlog_res_2 %>%  collect_metrics(summarize = FALSE)\n\n\n# A tibble: 32 × 5\n   id    .metric   .estimator .estimate .config             \n   <chr> <chr>     <chr>          <dbl> <chr>               \n 1 Fold2 recall    binary         0.812 Preprocessor1_Model1\n 2 Fold2 precision binary         0.807 Preprocessor1_Model1\n 3 Fold2 f_meas    binary         0.810 Preprocessor1_Model1\n 4 Fold2 accuracy  binary         0.809 Preprocessor1_Model1\n 5 Fold2 kap       binary         0.617 Preprocessor1_Model1\n 6 Fold2 sens      binary         0.812 Preprocessor1_Model1\n 7 Fold2 spec      binary         0.805 Preprocessor1_Model1\n 8 Fold2 roc_auc   binary         0.886 Preprocessor1_Model1\n 9 Fold3 recall    binary         0.832 Preprocessor1_Model1\n10 Fold3 precision binary         0.820 Preprocessor1_Model1\n# … with 22 more rows\n\n\n\n\nCollect predictions\nTo obtain the actual model predictions, we use the function collect_predictions and save the result as log_pred:\n\n\nShow the code\nlog_pred <- \n  log_res_2 %>%\n  collect_predictions()\n\n\n\n\nConfusion matrix\n\n\nShow the code\nlog_pred %>% \n  conf_mat(price_category, .pred_class) \n\n\n          Truth\nPrediction above below\n     above  3606   801\n     below   743  3542\n\n\n\n\nShow the code\nlog_pred %>% \n  conf_mat(price_category, .pred_class) %>% \n  autoplot(type = \"heatmap\")+\n  theme_minimal()\n\n\n\n\n\n\n\nROC Curve\n\n\nShow the code\nlog_pred %>% \n  group_by(id) %>% # id contains our folds\n  roc_curve(price_category, .pred_above) %>% \n  autoplot()+\n  theme_minimal()"
  },
  {
    "objectID": "posts/House Prices in Porltand/Portland Prices- Regression.html#use-the-workflow-to-train-our-model",
    "href": "posts/House Prices in Porltand/Portland Prices- Regression.html#use-the-workflow-to-train-our-model",
    "title": "House Prices in Porltand, OR",
    "section": "Use the workflow to train our model",
    "text": "Use the workflow to train our model\n\n\nShow the code\npdx_fit <- fit(pdx_wflow, train_data)\n\n\nThis allows us to use the model trained by this workflow to predict labels for our test set, and compare the performance metrics with the basic model we created previously.\n\n\nShow the code\npdx_fit %>% ## display results\npull_workflow_fit() %>%\ntidy()%>%\n  filter(p.value < 0.05)\n\n\n# A tibble: 6 × 5\n  term                 estimate std.error statistic       p.value\n  <chr>                   <dbl>     <dbl>     <dbl>         <dbl>\n1 yearBuilt              0.225     0.0413      5.45 0.0000000494 \n2 livingArea            -2.44      0.0475    -51.4  0            \n3 lotSize               -0.0566    0.0203     -2.80 0.00518      \n4 MiddleSchooldistance  -0.179     0.0311     -5.77 0.00000000773\n5 HighSchooldistance     0.0814    0.0303      2.69 0.00718      \n6 homeType_TOWNHOUSE     0.858     0.176       4.86 0.00000115   \n\n\n\n\nShow the code\nlibrary(vip) ##  the vip package helps us visualize the variable importance scores for the top features.\n\npdx_fit %>%\nextract_fit_parsnip() %>%\n   vip(num_features = 5)+\n  theme_minimal()\n\n\n\n\n\n\nMake predictions on the test set\n\n\nShow the code\npred_results <- test_data %>% \n  select(price_category) %>% \n  bind_cols(pdx_fit %>% \n              predict(new_data = test_data)) %>% \n  bind_cols(pdx_fit %>% \n              predict(new_data = test_data, type = \"prob\"))\n\n# Print the results\npred_results %>% \n  slice_head(n = 10)\n\n\n   price_category .pred_class .pred_above .pred_below\n1           below       above 0.798741282   0.2012587\n2           below       below 0.312220526   0.6877795\n3           below       below 0.490253446   0.5097466\n4           below       below 0.005902155   0.9940978\n5           below       below 0.036243773   0.9637562\n6           below       below 0.085069959   0.9149300\n7           below       below 0.050239248   0.9497608\n8           below       below 0.008699113   0.9913009\n9           below       below 0.022486738   0.9775133\n10          below       above 0.816183826   0.1838162\n\n\nLet’s take a look at the confusion matrix:\n\n\nShow the code\npred_results%>% \n  conf_mat(price_category, .pred_class) %>% \n  autoplot(type = \"heatmap\")+\n  theme_minimal()"
  },
  {
    "objectID": "posts/Time-Series/TimeSeries.html",
    "href": "posts/Time-Series/TimeSeries.html",
    "title": "Time Series Project",
    "section": "",
    "text": "In this project, I will perform Time series analysis using the Zillow Home Value Index (ZHVI) dataset: A smoothed, seasonally adjusted measure of the typical home value and market changes across Portland, OR, four bedroom houses. It reflects the typical value for homes in the 35th to 65th percentile range.\nHere is the link: https://www.zillow.com/research/data/"
  },
  {
    "objectID": "posts/Time-Series/TimeSeries.html#the-data",
    "href": "posts/Time-Series/TimeSeries.html#the-data",
    "title": "Time Series Project",
    "section": "The Data",
    "text": "The Data\n\n\nShow the code\nmetrofour <- read.csv(\"C:/Users/karol/Desktop/City_zhvi_bdrmcnt_4_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv\")\n\nstr(metrofour[,c(1:11)])\n\n\n'data.frame':   13513 obs. of  11 variables:\n $ RegionID   : int  6181 12447 39051 17426 6915 40326 13271 18959 54296 38128 ...\n $ SizeRank   : int  0 1 2 3 4 5 6 7 8 9 ...\n $ RegionName : chr  \"New York\" \"Los Angeles\" \"Houston\" \"Chicago\" ...\n $ RegionType : chr  \"city\" \"city\" \"city\" \"city\" ...\n $ StateName  : chr  \"NY\" \"CA\" \"TX\" \"IL\" ...\n $ State      : chr  \"NY\" \"CA\" \"TX\" \"IL\" ...\n $ Metro      : chr  \"New York-Newark-Jersey City, NY-NJ-PA\" \"Los Angeles-Long Beach-Anaheim, CA\" \"Houston-The Woodlands-Sugar Land, TX\" \"Chicago-Naperville-Elgin, IL-IN-WI\" ...\n $ CountyName : chr  \"Queens County\" \"Los Angeles County\" \"Harris County\" \"Cook County\" ...\n $ X2000.01.31: num  285211 302931 146651 181138 153807 ...\n $ X2000.02.29: num  287376 303230 146544 181616 154106 ...\n $ X2000.03.31: num  289205 304587 146194 182517 154357 ...\n\n\nWe have to make this dataset tidy. Tidy Data is a way of structuring data so that it can be easily understood by people and analyzed by machines.\nI need to remove the X at the beginning of the dates (X2000.01.31,X2000.02.29,…)\n\n\nShow the code\nnames(metrofour) <- sub(\"^X\", \"\", names(metrofour))\n\nstr(metrofour[,c(1:11)])\n\n\n'data.frame':   13513 obs. of  11 variables:\n $ RegionID  : int  6181 12447 39051 17426 6915 40326 13271 18959 54296 38128 ...\n $ SizeRank  : int  0 1 2 3 4 5 6 7 8 9 ...\n $ RegionName: chr  \"New York\" \"Los Angeles\" \"Houston\" \"Chicago\" ...\n $ RegionType: chr  \"city\" \"city\" \"city\" \"city\" ...\n $ StateName : chr  \"NY\" \"CA\" \"TX\" \"IL\" ...\n $ State     : chr  \"NY\" \"CA\" \"TX\" \"IL\" ...\n $ Metro     : chr  \"New York-Newark-Jersey City, NY-NJ-PA\" \"Los Angeles-Long Beach-Anaheim, CA\" \"Houston-The Woodlands-Sugar Land, TX\" \"Chicago-Naperville-Elgin, IL-IN-WI\" ...\n $ CountyName: chr  \"Queens County\" \"Los Angeles County\" \"Harris County\" \"Cook County\" ...\n $ 2000.01.31: num  285211 302931 146651 181138 153807 ...\n $ 2000.02.29: num  287376 303230 146544 181616 154106 ...\n $ 2000.03.31: num  289205 304587 146194 182517 154357 ...\n\n\n\n\nShow the code\nhouse_price <- metrofour %>% \n  pivot_longer(-c(RegionID, SizeRank, RegionName, RegionType, StateName, State, Metro, CountyName),\n    names_to = \"Monthly\",\n    values_to = \"Price\"\n  ) \nstr(metrofour[,c(1:11)])\n\n\n'data.frame':   13513 obs. of  11 variables:\n $ RegionID  : int  6181 12447 39051 17426 6915 40326 13271 18959 54296 38128 ...\n $ SizeRank  : int  0 1 2 3 4 5 6 7 8 9 ...\n $ RegionName: chr  \"New York\" \"Los Angeles\" \"Houston\" \"Chicago\" ...\n $ RegionType: chr  \"city\" \"city\" \"city\" \"city\" ...\n $ StateName : chr  \"NY\" \"CA\" \"TX\" \"IL\" ...\n $ State     : chr  \"NY\" \"CA\" \"TX\" \"IL\" ...\n $ Metro     : chr  \"New York-Newark-Jersey City, NY-NJ-PA\" \"Los Angeles-Long Beach-Anaheim, CA\" \"Houston-The Woodlands-Sugar Land, TX\" \"Chicago-Naperville-Elgin, IL-IN-WI\" ...\n $ CountyName: chr  \"Queens County\" \"Los Angeles County\" \"Harris County\" \"Cook County\" ...\n $ 2000.01.31: num  285211 302931 146651 181138 153807 ...\n $ 2000.02.29: num  287376 303230 146544 181616 154106 ...\n $ 2000.03.31: num  289205 304587 146194 182517 154357 ...\n\n\n\n\nShow the code\n#Converting the Date from factor to character\n\nhouse_clean <- house_price %>%\n            mutate(Monthly_parsed = as.Date(Monthly,\"%Y.%m.%d\"))\n\n\nhouse_clean[[\"Monthly\"]]<- as.character(house_clean$Monthly)\n\nhouse_price[[\"Monthly\"]]<- as.character(house_price $Monthly)\nsummary(house_clean)\n\n\n    RegionID         SizeRank      RegionName         RegionType       \n Min.   :  3300   Min.   :    0   Length:3702562     Length:3702562    \n 1st Qu.: 17364   1st Qu.: 3506   Class :character   Class :character  \n Median : 31949   Median : 7193   Mode  :character   Mode  :character  \n Mean   : 51588   Mean   : 8231                                        \n 3rd Qu.: 46308   3rd Qu.:11702                                        \n Max.   :827230   Max.   :28439                                        \n                                                                       \n  StateName            State              Metro            CountyName       \n Length:3702562     Length:3702562     Length:3702562     Length:3702562    \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n   Monthly              Price         Monthly_parsed      \n Length:3702562     Min.   :  18032   Min.   :2000-01-31  \n Class :character   1st Qu.: 172756   1st Qu.:2005-09-30  \n Mode  :character   Median : 244796   Median :2011-06-15  \n                    Mean   : 321468   Mean   :2011-06-15  \n                    3rd Qu.: 368862   3rd Qu.:2017-02-28  \n                    Max.   :8241271   Max.   :2022-10-31  \n                    NA's   :1195958                       \n\n\nWe see some missing values in the Price variable, but before I deal with those values, I will filter my data to the cities that I am interested the most\n\n\nShow the code\npdx_data <- house_clean %>%\n  dplyr:::filter(RegionID== 13373)  %>%\n  dplyr:::filter(Monthly_parsed >= \"2014-01-01\")\n\nsummary(pdx_data)\n\n\n    RegionID        SizeRank   RegionName         RegionType       \n Min.   :13373   Min.   :22   Length:106         Length:106        \n 1st Qu.:13373   1st Qu.:22   Class :character   Class :character  \n Median :13373   Median :22   Mode  :character   Mode  :character  \n Mean   :13373   Mean   :22                                        \n 3rd Qu.:13373   3rd Qu.:22                                        \n Max.   :13373   Max.   :22                                        \n  StateName            State              Metro            CountyName       \n Length:106         Length:106         Length:106         Length:106        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n   Monthly              Price        Monthly_parsed      \n Length:106         Min.   :411049   Min.   :2014-01-31  \n Class :character   1st Qu.:505802   1st Qu.:2016-04-07  \n Mode  :character   Median :564917   Median :2018-06-15  \n                    Mean   :562387   Mean   :2018-06-15  \n                    3rd Qu.:584219   3rd Qu.:2020-08-23  \n                    Max.   :759661   Max.   :2022-10-31  \n\n\nAfter filtering the data, we don’t have any missing values\n\nCoerce to a tsibble with as_tsibble()\nA time series can be recorded as a tsibble object in R. tsibble objects extend tidy data frames (tibble objects) by introducing temporal structure, and to do it, we need to declare key and index. In this case, the Monthly_parsed containing the data-time is the index and the RegionID is the key. Other columns can be considered as measured variables.\n\n\nShow the code\ntsb_pdx <- pdx_data %>%\n                   select(RegionName,RegionID, Monthly_parsed, Price)\n\ntsb_pref_pdx <-tsb_pdx%>%\n  as_tsibble(key= RegionName, index= Monthly_parsed)%>%\n                   index_by(year_month = ~ yearmonth(.))\n\ntsibble_pdx <-tsb_pref_pdx%>%\n  select(-RegionID)%>%\n  as_tsibble(key= RegionName, index= year_month)%>%\n  mutate(Prices = Price/1000)"
  },
  {
    "objectID": "posts/Time-Series/TimeSeries.html#data-visualization",
    "href": "posts/Time-Series/TimeSeries.html#data-visualization",
    "title": "Time Series Project",
    "section": "Data Visualization",
    "text": "Data Visualization\nTo visualize the data, I could use the autoplot() command, but I rather to create my graph with ggplot.\n\n\nShow the code\nplot_pdx_house <- tsibble_pdx %>%\n  ggplot(aes(x= year_month, y= Prices)) +\n  geom_line(size=1, color= \"darkgreen\")+\n   \n    labs(y=\"Price in Thousands of Dollars \", \n       x= \" \",\n       title=\" Four Bedroom House Prices in Portland, OR, 2012-2022 \",\n       caption = \"data:https://www.zillow.com/research/data\")+\n  scale_y_continuous(labels=scales::dollar_format())+\n  theme_minimal()\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nShow the code\nplot_pdx_house \n\n\n\n\n\nData is non- stationary, we can see a trend-cycle component in the graph above.\n\n\nShow the code\ntsibble_pdx %>%\ngg_subseries(Price/1000)+\n  labs(y= \"Price in Thousands of Dollars\",\n       x= \"Year\")+theme_minimal()+\n  scale_y_continuous(labels=scales::dollar_format())+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n\n\n\n\nShow the code\ntsibble_pdx%>%\ngg_season(Price/1000, labels = \"both\")+\n  labs(x= \"\",\n       y= \"Price in Thousands of Dollars \", \n       title=\"Portland's Seasonal Plot\")+\n  \n  scale_y_continuous(labels=scales::dollar_format())+\n  theme_minimal()"
  },
  {
    "objectID": "posts/Time-Series/TimeSeries.html#determining-stationarity",
    "href": "posts/Time-Series/TimeSeries.html#determining-stationarity",
    "title": "Time Series Project",
    "section": "Determining Stationarity",
    "text": "Determining Stationarity\nIn our analysis, we use the Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test (Kwiatkowski et al., 1992). In this test, the null hypothesis is that the data are stationary, and we look for evidence that the null hypothesis is false. Consequently, small p-values (e.g., less than 0.05) suggest that differencing is required. The test can be computed using the unitroot_kpss() function.\n\n\nShow the code\ntsibble_pdx%>%\n  features(Prices, unitroot_kpss)\n\n\n# A tibble: 1 × 3\n  RegionName kpss_stat kpss_pvalue\n  <chr>          <dbl>       <dbl>\n1 Portland        1.95        0.01\n\n\nThe p-value is reported as 0.01 if it is less than 0.01, and as 0.1 if it is greater than 0.1. In this case, the test statistic (1.946) is bigger than the 1% critical value, so the p-value is less than 0.01, indicating that the null hypothesis is rejected. That is, the data are not stationary.\n\n\nShow the code\ntsibble_pdx %>% \n  features(Prices ,unitroot_ndiffs)\n\n\n# A tibble: 1 × 2\n  RegionName ndiffs\n  <chr>       <int>\n1 Portland        1\n\n\nAs we saw from the KPSS tests above, one difference (d) is required to make the tsibble_pdx data stationary."
  },
  {
    "objectID": "posts/Time-Series/TimeSeries.html#autocorrelation",
    "href": "posts/Time-Series/TimeSeries.html#autocorrelation",
    "title": "Time Series Project",
    "section": "Autocorrelation",
    "text": "Autocorrelation\n\n\nShow the code\ntsibble_pdx %>%\n  gg_tsdisplay(Prices,\n                     plot_type='partial')+\n       labs(y=\"Thousands of Dollars \", \n       x= \" \")\n\n\n\n\n\nACF does not drop quickly to zero, moreover the value is large and positive (almost 1 in this case). All these are signs of a non-stationary time series. Therefore it should be differenced to obtain a stationary series.\nPACF value r1 is almost 1. All other values ri,i >1 are small. This is a sign of a non stationary process that should be differenced in order to obtain a stationary series.\nThe data are clearly non-stationary, so we will first take a seasonal difference. The seasonally differenced data are shown below:\n\n\nShow the code\ntsibble_pdx %>%\n  gg_tsdisplay(difference(Prices, 12),\n               plot_type='partial', lag=36) +\n  labs(title=\"Seasonally differenced\", y=\"\")\n\n\nWarning: Removed 12 rows containing missing values (`geom_line()`).\n\n\nWarning: Removed 12 rows containing missing values (`geom_point()`).\n\n\n\n\n\nThese are also clearly non-stationary, so we take a further first difference\n\n\nShow the code\ntsibble_pdx %>%\n  gg_tsdisplay(difference(Prices, 12) %>% difference(),\n               plot_type='partial', lag=36) +\n  labs(title = \"Double differenced\", y=\"\")\n\n\nWarning: Removed 13 rows containing missing values (`geom_line()`).\n\n\nWarning: Removed 13 rows containing missing values (`geom_point()`).\n\n\n\n\n\nOur aim now is to find an appropriate ARIMA model based on the ACF and PACF shown in the Double Differenced graph."
  },
  {
    "objectID": "posts/Time-Series/TimeSeries.html#seasonal-arima-model",
    "href": "posts/Time-Series/TimeSeries.html#seasonal-arima-model",
    "title": "Time Series Project",
    "section": "Seasonal Arima Model",
    "text": "Seasonal Arima Model\n\n\nShow the code\nall_fit <- tsibble_pdx%>%\n  model(\n    arima212012 = ARIMA(Prices ~ pdq(2,1,2)+ PDQ(0,1,2)),\n    arima210011 = ARIMA(Prices ~ pdq(2,1,0)+ PDQ(0,1,1)),\n    stepwise = ARIMA(Prices),\n    search = ARIMA(Prices,stepwise=FALSE))\n\n\n\n\nShow the code\nall_fit %>% pivot_longer(!RegionName,\n            names_to = \"Model name\", \n            values_to = \"Orders\")\n\n\n# A mable: 4 x 3\n# Key:     RegionName, Model name [4]\n  RegionName `Model name`                             Orders\n  <chr>      <chr>                                   <model>\n1 Portland   arima212012           <ARIMA(2,1,2)(0,1,2)[12]>\n2 Portland   arima210011           <ARIMA(2,1,0)(0,1,1)[12]>\n3 Portland   stepwise                <ARIMA(3,1,2) w/ drift>\n4 Portland   search       <ARIMA(2,1,3)(0,0,1)[12] w/ drift>\n\n\n\n\nShow the code\nglance(all_fit) %>% arrange(AICc) %>% select(.model:BIC)\n\n\n# A tibble: 4 × 6\n  .model      sigma2 log_lik   AIC  AICc   BIC\n  <chr>        <dbl>   <dbl> <dbl> <dbl> <dbl>\n1 arima212012   2.86   -189.  391.  392.  409.\n2 search        2.17   -190.  396.  398.  418.\n3 stepwise      2.25   -193.  399.  400.  418.\n4 arima210011   4.58   -205.  419.  419.  429.\n\n\nOf these models, the best is the ARIMA(2,1,2)(0,1,2)[12]model (i.e., it has the smallest AICc value).\n\n\nShow the code\narima212012 <- tsibble_pdx %>%\n  model(arima212012 = ARIMA(Prices ~ pdq(2,1,2)+ PDQ(0,1,2)))%>%\n  report()\n\n\nSeries: Prices \nModel: ARIMA(2,1,2)(0,1,2)[12] \n\nCoefficients:\n         ar1     ar2     ma1     ma2     sma1    sma2\n      0.5148  0.0355  1.0100  0.9999  -0.8229  0.1287\ns.e.  0.1145  0.1214  0.0582  0.0709   0.1477  0.1514\n\nsigma^2 estimated as 2.856:  log likelihood=-188.55\nAIC=391.09   AICc=392.41   BIC=408.82\n\n\n\n\nShow the code\nall_fit %>% select(arima212012) %>%\n  gg_tsresiduals()\n\n\n\n\n\n\n\nShow the code\naugment(all_fit) %>%\n  filter(.model=='arima212012') %>%\n  features(.innov, ljung_box, lag = 36, dof = 6)\n\n\n# A tibble: 1 × 4\n  RegionName .model      lb_stat lb_pvalue\n  <chr>      <chr>         <dbl>     <dbl>\n1 Portland   arima212012    37.3     0.170\n\n\n\n\nShow the code\ntsibble_pdx %>%\n  model(ARIMA(Prices ~ pdq(2,1,2) + PDQ(0,1,2))) %>%\n  forecast() %>%\n  autoplot(tsibble_pdx) +\n  labs(y=\" Thousands of $US \",\n       x =\" \",\n       title=\"Forecast from the ARIMA(2,1,2)(0,1,2)[12] model\\napplied to the Portland House Prices data\")\n\n\n`mutate_if()` ignored the following grouping variables:\n• Column `year_month`\n\n\n\n\n\nShow the code\n##Price in Thousands of Dollars\ntsibble_pdx %>%\n  model(ARIMA(Prices ~ pdq(2,1,2) + PDQ(0,1,2))) %>%\n  forecast()\n\n\n# A fable: 24 x 5 [1M]\n# Key:     RegionName, .model [1]\n   RegionName .model                                  year_m…¹      Prices .mean\n   <chr>      <chr>                                      <mth>      <dist> <dbl>\n 1 Portland   ARIMA(Prices ~ pdq(2, 1, 2) + PDQ(0, 1… 2022 Nov   N(737, 3)  737.\n 2 Portland   ARIMA(Prices ~ pdq(2, 1, 2) + PDQ(0, 1… 2022 Dec  N(737, 22)  737.\n 3 Portland   ARIMA(Prices ~ pdq(2, 1, 2) + PDQ(0, 1… 2023 Jan  N(739, 76)  739.\n 4 Portland   ARIMA(Prices ~ pdq(2, 1, 2) + PDQ(0, 1… 2023 Feb N(742, 157)  742.\n 5 Portland   ARIMA(Prices ~ pdq(2, 1, 2) + PDQ(0, 1… 2023 Mar N(748, 257)  748.\n 6 Portland   ARIMA(Prices ~ pdq(2, 1, 2) + PDQ(0, 1… 2023 Apr N(753, 369)  753.\n 7 Portland   ARIMA(Prices ~ pdq(2, 1, 2) + PDQ(0, 1… 2023 May N(758, 487)  758.\n 8 Portland   ARIMA(Prices ~ pdq(2, 1, 2) + PDQ(0, 1… 2023 Jun N(761, 609)  761.\n 9 Portland   ARIMA(Prices ~ pdq(2, 1, 2) + PDQ(0, 1… 2023 Jul N(764, 734)  764.\n10 Portland   ARIMA(Prices ~ pdq(2, 1, 2) + PDQ(0, 1… 2023 Aug N(765, 860)  765.\n# … with 14 more rows, and abbreviated variable name ¹​year_month"
  },
  {
    "objectID": "posts/Time-Series/TimeSeries.html#ets",
    "href": "posts/Time-Series/TimeSeries.html#ets",
    "title": "Time Series Project",
    "section": "ETS",
    "text": "ETS\n\n\nShow the code\nfit_ets <- tsibble_pdx %>%\n  model(ETS(Prices))\nreport(fit_ets)\n\n\nSeries: Prices \nModel: ETS(M,Ad,N) \n  Smoothing parameters:\n    alpha = 0.9999 \n    beta  = 0.9987271 \n    phi   = 0.9108026 \n\n  Initial states:\n     l[0]     b[0]\n 407.9964 3.526883\n\n  sigma^2:  0\n\n     AIC     AICc      BIC \n650.8419 651.6904 666.8225 \n\n\nThe model selected is ETS(M,Ad,N)\n\n\nShow the code\ncomponents(fit_ets) %>%\n  autoplot() +\n  labs(title = \"ETS(M,Ad,N) components\")\n\n\nWarning: Removed 1 row containing missing values (`geom_line()`).\n\n\n\n\n\nBecause this model has multiplicative errors, the innovation residuals are not equivalent to the regular residuals.\n\n\nShow the code\nfit_ets %>%\n    augment() %>%\n    select(.innov, .resid) %>%\n    pivot_longer(c(.innov, .resid)) %>%\n    autoplot()\n\n\nPlot variable not specified, automatically selected `.vars = value`\n\n\n\n\n\n\n\nShow the code\nfit_ets%>%\n    gg_tsresiduals()\n\n\n\n\n\n\n\nShow the code\nfit_ets %>%\n  forecast(h = 24) %>%\n  autoplot(tsibble_pdx)\n\n\n`mutate_if()` ignored the following grouping variables:\n• Column `year_month`\n\n\n\n\n\n\n\nShow the code\nbind_rows(\n    arima212012 %>% accuracy(),\n    fit_ets %>% accuracy()) %>%\n  select(-ME, -MPE, -ACF1)\n\n\n# A tibble: 2 × 8\n  RegionName .model      .type     RMSE   MAE  MAPE   MASE  RMSSE\n  <chr>      <chr>       <chr>    <dbl> <dbl> <dbl>  <dbl>  <dbl>\n1 Portland   arima212012 Training  1.53  1.14 0.194 0.0286 0.0310\n2 Portland   ETS(Prices) Training  2.27  1.60 0.271 0.0403 0.0459\n\n\nIn this case the ARIMA model seems to be more accurate model based on the test set RMSE, MAPE and MASE."
  }
]