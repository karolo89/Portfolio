[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Portfolio",
    "section": "",
    "text": "Dec 4, 2022\n\n\nKarol Orozco\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\nKarol Orozco\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOct 21, 2022\n\n\nKarol Orozco\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOct 21, 2022\n\n\nKarol Orozco\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOct 1, 2022\n\n\nKarol Orozco\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Employee Turnover/Analyzing Employee Turnover.html",
    "href": "posts/Employee Turnover/Analyzing Employee Turnover.html",
    "title": "Predicting Employee Attrition",
    "section": "",
    "text": "You work for the human capital department of a large corporation. The Board is worried about the relatively high turnover, and your team must look into ways to reduce the number of employees leaving the company. The team needs to understand better the situation, which employees are more likely to leave, and why. Once it is clear what variables impact employee churn, you can present your findings along with your ideas on how to attack the problem.\n\n\nCreate a report that covers the following:\n\nWhich designation has the highest employee turnover? Which one has the lowest?\nInvestigate which variables seem to be better predictors of employee departure.\nWhat recommendations would you make regarding ways to reduce employee turnover?"
  },
  {
    "objectID": "posts/Employee Turnover/Analyzing Employee Turnover.html#get-the-data",
    "href": "posts/Employee Turnover/Analyzing Employee Turnover.html#get-the-data",
    "title": "Predicting Employee Attrition",
    "section": "2. Get the Data",
    "text": "2. Get the Data\n\n\n  X     MMM.YY Emp_ID Age Gender City Education_Level Salary Dateofjoining\n1 1 2016-01-01      1  28   Male  C23          Master  57387    2015-12-24\n2 2 2016-02-01      1  28   Male  C23          Master  57387    2015-12-24\n3 3 2016-03-01      1  28   Male  C23          Master  57387    2015-12-24\n4 4 2017-11-01      2  31   Male   C7          Master  67016    2017-11-06\n5 5 2017-12-01      2  31   Male   C7          Master  67016    2017-11-06\n6 6 2016-12-01      4  43   Male  C13          Master  65603    2016-12-07\n  LastWorkingDate Joining.Designation Designation Total.Business.Value\n1            <NA>                   1           1              2381060\n2            <NA>                   1           1              -665480\n3      2016-03-11                   1           1                    0\n4            <NA>                   2           2                    0\n5            <NA>                   2           2                    0\n6            <NA>                   2           2                    0\n  Quarterly.Rating\n1                2\n2                2\n3                2\n4                1\n5                1\n6                1\n\n\n\nThe variables are defined as follow:\n\nMMMM-YY: Reporting Date (Monthly)\nEmp_ID: Unique id for employees\nAge: ge of the employee\nGender: Gender of the employee\nCity: City Code of the employee\nEducation_Level: Education level : Bachelor, Master or College\nSalary: Salary of the employee\nDateofjoining: Joining date for the employee\nLastWorkingDate: Last date of working for the employee\nJoining Designation: Designation of the employee at the time of joining\nDesignation: Designation of the employee at the time of reporting\nTotalBusinessValue: The total business value acquired by the employee in a month (negative business indicates cancellation/refund of sold insurance policies)\nQuarterly Rating: Quarterly rating of the employee: 1,2,3,4 (higher is better)"
  },
  {
    "objectID": "posts/Employee Turnover/Analyzing Employee Turnover.html#prepare-and-analyze-the-data",
    "href": "posts/Employee Turnover/Analyzing Employee Turnover.html#prepare-and-analyze-the-data",
    "title": "Predicting Employee Attrition",
    "section": "3. Prepare and Analyze the Data",
    "text": "3. Prepare and Analyze the Data\n\nThis dataset contains 19104 obs. of 13 variables. We see some duplicate Employees ID, and we should remove them\n\n\n\n\nNow we have 2,381 rows\n\n\n      X                 MMM.YY              Emp_ID               Age       \n Length:2381        Min.   :2016-01-01   Length:2381        Min.   :21.00  \n Class :character   1st Qu.:2016-01-01   Class :character   1st Qu.:29.00  \n Mode  :character   Median :2016-07-01   Mode  :character   Median :33.00  \n                    Mean   :2016-08-29                      Mean   :33.09  \n                    3rd Qu.:2017-05-01                      3rd Qu.:37.00  \n                    Max.   :2017-12-01                      Max.   :58.00  \n                                                                           \n    Gender         City           Education_Level     Salary      \n Female: 977   Length:2381        Bachelor:795    Min.   : 10747  \n Male  :1404   Class :character   College :784    1st Qu.: 39104  \n               Mode  :character   Master  :802    Median : 55276  \n                                                  Mean   : 59209  \n                                                  3rd Qu.: 75765  \n                                                  Max.   :188418  \n                                                                  \n Dateofjoining        LastWorkingDate      Joining.Designation Designation\n Min.   :2010-04-01   Min.   :2015-12-31   1:1026              1:751      \n 1st Qu.:2015-06-29   1st Qu.:2016-01-07   2: 815              2:866      \n Median :2016-07-21   Median :2016-01-19   3: 493              3:611      \n Mean   :2016-02-08   Mean   :2016-03-12   4:  36              4:132      \n 3rd Qu.:2017-05-02   3rd Qu.:2016-01-26   5:  11              5: 21      \n Max.   :2017-12-28   Max.   :2017-12-18                                  \n                      NA's   :2279                                        \n Total.Business.Value Quarterly.Rating\n Min.   :-1590270     1:1649          \n 1st Qu.:       0     2: 411          \n Median :       0     3: 216          \n Mean   :  291175     4: 105          \n 3rd Qu.:  250590                     \n Max.   :10398160                     \n                                      \n\n\n\nThe median age is 33 years old\nNow, we need to know that in order to predict if the employee will leave the company or not can be best predicted if we have last working day info available and hence although the missing percentage is high, it’s not because of Null values but the employees are not planning to leave the company and hence have not provided the info.Therefore we should not remove this feature from our data, instead we need to treat this as our target variable.\nSalary goes from 10747 to 188418 dollars\nMost of the employees have a Master degree\n\n\n\nShow the code\nempl_churn <- empl_turnover %>% mutate(Churn=  ifelse(is.na(LastWorkingDate), \"No\", \"Yes\"))\n\nempl_churn$Churn.Numeric <- as.numeric(as.factor(empl_churn$Churn))-1\n\nglimpse(empl_churn)\n\n\nRows: 2,381\nColumns: 16\n$ X                    <chr> \"1\", \"4\", \"6\", \"11\", \"14\", \"19\", \"22\", \"23\", \"29\"…\n$ MMM.YY               <date> 2016-01-01, 2017-11-01, 2016-12-01, 2016-01-01, …\n$ Emp_ID               <chr> \"1\", \"2\", \"4\", \"5\", \"6\", \"8\", \"11\", \"12\", \"13\", \"…\n$ Age                  <int> 28, 31, 43, 29, 31, 34, 28, 35, 29, 39, 30, 42, 2…\n$ Gender               <fct> Male, Male, Male, Male, Female, Male, Female, Mal…\n$ City                 <chr> \"C23\", \"C7\", \"C13\", \"C9\", \"C11\", \"C2\", \"C19\", \"C2…\n$ Education_Level      <fct> Master, Master, Master, College, Bachelor, Colleg…\n$ Salary               <int> 57387, 67016, 65603, 46368, 78728, 70656, 42172, …\n$ Dateofjoining        <date> 2015-12-24, 2017-11-06, 2016-12-07, 2016-01-09, …\n$ LastWorkingDate      <date> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Joining.Designation  <fct> 1, 2, 2, 1, 3, 3, 1, 1, 1, 3, 2, 1, 1, 3, 1, 1, 1…\n$ Designation          <fct> 1, 2, 2, 1, 3, 3, 1, 1, 4, 3, 2, 1, 1, 3, 1, 1, 2…\n$ Total.Business.Value <int> 2381060, 0, 0, 0, 0, 0, 0, 500000, 250000, 0, 346…\n$ Quarterly.Rating     <fct> 2, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 2, 1, 1, 4, 2, 2…\n$ Churn                <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"…\n$ Churn.Numeric        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\nTurnover\nNumber of employees that left the company:\nThe overall attrition rate in the company in average is 4.28%, which means that 102 employees have left the company during 2016-2017.``\n\n\nShow the code\ntable(empl_churn$Churn)\n\n\n\n  No  Yes \n2279  102 \n\n\n\n\nShow the code\nggplot(empl_churn,aes(x = Churn, group = Gender)) + \n    geom_bar(aes(y = ..prop.., fill = factor(..x..)), \n    stat=\"count\", color = \"black\", alpha = 0.7) +\n  \n    geom_text(aes(label = scales::percent(..prop..),\n    y= ..prop.. ), stat= \"count\", position = position_stack(vjust = 0.5), size = 4.5) +\n  \n    facet_grid(~Gender) +\n  \n    scale_y_continuous(labels = scales::percent)+\n\n    guides(fill = F)+\n    labs(\n    x = \"Left\", y = \"Percentage\",\n    title=\"Turnover Proportion by Gender\")+\n   scale_fill_manual(values=c(\"gray\", \"#2166AC\"))+\n    theme(text = element_text(size = 12), \n    plot.title = element_text(hjust = 0.5), \n    title = element_text(size = 12))+\n\n\n ggpubr::theme_pubclean()\n\n\n\n\n\nThere is a small difference in the proportion of women and men that left the company.\n\n\nShow the code\nempl_turnover_prop <- empl_churn %>% \n  tabyl(Designation, Churn) %>%\n  adorn_percentages(\"row\") \nkable(empl_turnover_prop,  caption = \"Designation vs Attrition\")\n\n\n\nDesignation vs Attrition\n\n\nDesignation\nNo\nYes\n\n\n\n\n1\n0.9227696\n0.0772304\n\n\n2\n0.9607390\n0.0392610\n\n\n3\n0.9852700\n0.0147300\n\n\n4\n1.0000000\n0.0000000\n\n\n5\n0.9523810\n0.0476190\n\n\n\n\n\n\nThe data shows that Destination 1 and 5 has the highest employee turnover rate, destination 4 and 3 has the lowest rate.\n\n\n\nAttrition vs Age\nThe majority of employees that left the organization are in their 30’s , and the proportion steadily declined.\n\n\nShow the code\n### Age vs Turnover\n\n\nempl_churn %>%\ngroup_by(Age, Churn)%>%\nggplot(aes(x = Age, fill = Churn)) +\ngeom_histogram(bins = 30L) +\n\nscale_fill_manual(values=c(\"gray\", \"#2166AC\"))+\n\n ggpubr::theme_pubclean()+\n\n\n  labs( x= \"Age\",\n        y= \"Number of Employees\",\n        title = \"Attrition vs Age\")+\n\ntheme(plot.title = element_text(size =12, face = \"bold\", hjust = 0.45),\nlegend.position=\"bottom\")"
  },
  {
    "objectID": "posts/Employee Turnover/Analyzing Employee Turnover.html#education-vs-churn",
    "href": "posts/Employee Turnover/Analyzing Employee Turnover.html#education-vs-churn",
    "title": "Predicting Employee Attrition",
    "section": "Education vs Churn",
    "text": "Education vs Churn\n\n\nShow the code\nresult <- compare_props(\n  empl_churn, \n  var1 = \"Education_Level\", \n  var2 = \"Churn\", \n  levs = \"No\", \n  comb = \"Bachelor:College\"\n)\nsummary(result, show = FALSE)\n\n\nPairwise proportion comparisons\nData      : empl_churn \nVariables : Education_Level, Churn \nLevel     : No in Churn \nConfidence: 0.95 \nAdjustment: None \n\n Education_Level  No Yes     p   n n_missing    sd    se    me\n        Bachelor 766  29 0.964 795         0 0.187 0.007 0.013\n         College 740  44 0.944 784         0 0.230 0.008 0.016\n          Master 773  29 0.964 802         0 0.187 0.007 0.013\n\n Null hyp.            Alt. hyp.                       diff p.value  \n Bachelor = College   Bachelor not equal to College   0.02 0.063   .\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nShow the code\nplot(result, plots = \"dodge\", custom = TRUE)+\n\nscale_fill_manual(values=c(\"gray\", \"#2166AC\"))+\n\n ggpubr::theme_pubclean()+\n\n\n  labs( x= \" \",\n        y= \"% of Churn\",\n        title = \"Attrition vs Education\")+\n\ntheme(plot.title = element_text(size =12, face = \"bold\", hjust = 0.45),\nlegend.position=\"bottom\")\n\n\n\n\n\n\nEmployees with College degree have the highest number of people living the company\n\n\n\nShow the code\nlibrary(corrplot)\nGGally::ggpairs(empl_churn[, unlist(lapply(empl_churn, is.numeric))])"
  },
  {
    "objectID": "posts/Employee Turnover/Analyzing Employee Turnover.html#the-model--binary-logistic-regression-for-churn-prediction",
    "href": "posts/Employee Turnover/Analyzing Employee Turnover.html#the-model--binary-logistic-regression-for-churn-prediction",
    "title": "Predicting Employee Attrition",
    "section": "4. The Model- Binary Logistic regression for churn prediction",
    "text": "4. The Model- Binary Logistic regression for churn prediction\n\n\nShow the code\nggplot(empl_churn) +\n aes(x = Salary, y = Churn, fill = Churn) +\n geom_boxplot() +\nscale_fill_manual(values=c(\"gray\", \"#2166AC\"))+\n ggpubr::theme_pubclean()"
  },
  {
    "objectID": "posts/Instacart/index.knit.html",
    "href": "posts/Instacart/index.knit.html",
    "title": "Instacart",
    "section": "",
    "text": "The data analyzed came for kaggle, https://www.kaggle.com/c/instacart-market-basket-analysis/data. The dataset is anonymized and contains a sample of over 3 million grocery orders from more than 200,000 Instacart users\nOnce the dataset is downloaded, it weighs 200.7 MB in zip format. Once unzipped, six files appear:\n\ndepartments.csv: Collect name and id for different departments.\naisle.csv: That collects the corridors and the different sections.\nproducts.csv: Collect all the products that are for sale in the store.\norders.csv: Collect all the orders made by customers, or which is the same, all the shopping carts (Market_Basket).\norder_products_prior.csv: Collect the products that were purchased in an order and all the customer’s purchase history throughout that year.\norder_products_train.csv: Collect the products that were purchased in an order reflecting the last basket purchased by each customer.\n\nFor this analysis, we will use the order_products_train.csv, which offers a data sample of the order_products_prior.csv"
  },
  {
    "objectID": "posts/Instacart/index.knit.html#prepare-and-analyze-the-data",
    "href": "posts/Instacart/index.knit.html#prepare-and-analyze-the-data",
    "title": "Instacart",
    "section": "Prepare and Analyze the Data",
    "text": "Prepare and Analyze the Data\nLoad the data: Departments, order_products, orders, products and aisles\n\n\nShow the code\ndepartments <- read.csv(\"C:/Users/karol/Desktop/DATA/INSTA/departments.csv\")\norder_products <- read.csv(\"C:/Users/karol/Desktop/DATA/INSTA/order_products__train.csv\")\norders <- read.csv(\"C:/Users/karol/Desktop/DATA/INSTA/orders.csv\")\nproducts <- read.csv(\"C:/Users/karol/Desktop/DATA/INSTA/products.csv\")\naisles <- read.csv(\"C:/Users/karol/Desktop/DATA/INSTA/aisles.csv\")\n\n\n\nDepartments\n\n\nShow the code\nglimpse(departments)\n\n\nRows: 21\nColumns: 2\n$ department_id <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ department    <chr> \"frozen\", \"other\", \"bakery\", \"produce\", \"alcohol\", \"inte…\n\n\n\n\nOrder Products\n\n\nShow the code\nglimpse(order_products)\n\n\nRows: 1,384,617\nColumns: 4\n$ order_id          <int> 1, 1, 1, 1, 1, 1, 1, 1, 36, 36, 36, 36, 36, 36, 36, …\n$ product_id        <int> 49302, 11109, 10246, 49683, 43633, 13176, 47209, 220…\n$ add_to_cart_order <int> 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2…\n$ reordered         <int> 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0…\n\n\n\n\nOrders\n\n\nShow the code\nglimpse(orders)\n\n\nRows: 3,421,083\nColumns: 7\n$ order_id               <int> 2539329, 2398795, 473747, 2254736, 431534, 3367…\n$ user_id                <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2,…\n$ eval_set               <chr> \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"p…\n$ order_number           <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1, 2, 3, 4, …\n$ order_dow              <int> 2, 3, 3, 4, 4, 2, 1, 1, 1, 4, 4, 2, 5, 1, 2, 3,…\n$ order_hour_of_day      <int> 8, 7, 12, 7, 15, 7, 9, 14, 16, 8, 8, 11, 10, 10…\n$ days_since_prior_order <dbl> NA, 15, 21, 29, 28, 19, 20, 14, 0, 30, 14, NA, …\n\n\n\n\nProducts\n\n\nShow the code\nglimpse(products)\n\n\nRows: 49,688\nColumns: 4\n$ product_id    <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ product_name  <chr> \"Chocolate Sandwich Cookies\", \"All-Seasons Salt\", \"Robus…\n$ aisle_id      <int> 61, 104, 94, 38, 5, 11, 98, 116, 120, 115, 31, 119, 11, …\n$ department_id <int> 19, 13, 7, 1, 13, 11, 7, 1, 16, 7, 7, 1, 11, 17, 18, 19,…\n\n\n\n\nAisles\n\n\nShow the code\nglimpse(aisles)\n\n\nRows: 134\nColumns: 2\n$ aisle_id <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ aisle    <chr> \"prepared soups salads\", \"specialty cheeses\", \"energy granola…\n\n\n\nCombining and Transforming the data\n\n\nShow the code\norders$order_hour_of_day <- as.numeric(orders$order_hour_of_day)\n\nproducts <- products%>% mutate(category =  ifelse(grepl(\"Organic\", products$product_name), \"Organic\",  \"Non-organic\"))\ndf <- products %>% group_by(department_id, aisle_id, product_id, product_name, category) %>% dplyr::summarize(n=n())\n\n\ndf <- df %>% left_join(departments,by=\"department_id\")\ndf<-  df %>% left_join(aisles,by=\"aisle_id\")\ndata <- merge(x= order_products,y= df, by= \"product_id\")\ndata <- merge(x= data, y= orders, by= \"order_id\")\n\n\nproducts <- products %>% mutate(product_name = as.factor(product_name))\n\naisles <- aisles %>% mutate(aisle = as.factor(aisle))\ndepartments <- departments %>% mutate(department = as.factor(department))\ndata <- data %>% mutate(product_name = as.factor(product_name))\ndata <- data %>% mutate(order_id = as.character(order_id))\ndata <- data %>% mutate(add_to_cart_order = as.factor(add_to_cart_order))\ndata <- data %>% mutate(reordered = as.factor(reordered))\n\n\n\n\nShow the code\nstr(data)\n\n\n'data.frame':   1384617 obs. of  17 variables:\n $ order_id              : chr  \"1\" \"1\" \"1\" \"1\" ...\n $ product_id            : int  13176 49302 22035 11109 47209 49683 43633 10246 43086 39612 ...\n $ add_to_cart_order     : Factor w/ 80 levels \"1\",\"2\",\"3\",\"4\",..: 6 1 8 2 7 4 5 3 4 1 ...\n $ reordered             : Factor w/ 2 levels \"0\",\"1\": 1 2 2 2 1 1 2 1 2 1 ...\n $ department_id         : int  4 16 16 16 4 4 15 4 4 16 ...\n $ aisle_id              : int  24 120 21 108 24 83 95 83 123 2 ...\n $ product_name          : Factor w/ 39123 levels \"#2 Coffee Filters\",..: 2635 4507 25657 22359 23761 9089 18248 22851 34372 14425 ...\n $ category              : chr  \"Organic\" \"Non-organic\" \"Organic\" \"Organic\" ...\n $ n                     : int  1 1 1 1 1 1 1 1 1 1 ...\n $ department            : chr  \"produce\" \"dairy eggs\" \"dairy eggs\" \"dairy eggs\" ...\n $ aisle                 : chr  \"fresh fruits\" \"yogurt\" \"packaged cheese\" \"other creams cheeses\" ...\n $ user_id               : int  112108 112108 112108 112108 112108 112108 112108 112108 79431 79431 ...\n $ eval_set              : chr  \"train\" \"train\" \"train\" \"train\" ...\n $ order_number          : int  4 4 4 4 4 4 4 4 23 23 ...\n $ order_dow             : int  4 4 4 4 4 4 4 4 6 6 ...\n $ order_hour_of_day     : num  10 10 10 10 10 10 10 10 18 18 ...\n $ days_since_prior_order: num  9 9 9 9 9 9 9 9 30 30 ...\n\n\n\n\n\nData Exploration\nMaximum number of orders are placed between 9:00am and 4:00pm on Sunday and Monday. There is also a big number of orders during Friday and Saturday.\n\n\nShow the code\nday_week <- orders %>%\n    mutate(day = as.factor(order_dow)) %>%\n    mutate(hour = as.factor(order_hour_of_day)) %>%\n    group_by(day,hour) %>%\n    dplyr::summarise(count = n()) %>%\n    arrange(desc(count))\n\nday_weekp <-day_week %>%\n    ggplot(aes(x=day, y=hour))+\n    geom_tile(aes(fill=count), colour = \"white\") + \n  \n    scale_fill_gradient(name= \"Number of\\nOrders\", \n                        low = \"#FFF5EE\",\n                        high = \"#CC5500\")+\n    scale_x_discrete( position = \"top\",\n                    breaks = c(\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\"),\n                    label = c(\"Sunday\", \"Monday\", \"Tuesday\",\n                              \"Wednesday\",\"Thursday\", \"Friday\", \"Saturday\"),\n                    expand=c(0,0))+\n    scale_y_discrete( \n                    breaks = c(\"0\", \"6\", \"12\", \"18\", \"23\"),\n                    label = c(\"12am\", \"6am\", \"12pm\", \"6pm\", \"11pm\"),\n                    expand=c(0,0))+\n  \n    labs(title=\"Which Day and What Time Do Customers Order the Most?\",\n            x=\"\", \n            y=\"\")+\n  \n    ggpubr::theme_pubclean()+\n    theme(\n      \n    axis.line=element_blank(),                                               \n    axis.ticks=element_line(size=0.4),\n    axis.text = element_text(size= 10),\n\n    plot.background=element_blank(),         \n    plot.title = element_text(size =10, hjust = 0.50, vjust = 1),\n    plot.caption = element_text(hjust = 0, size = 5, \n                                margin = unit(c(0.5, 0.5, 0.5, 0.5), \"cm\")),\n\n    \n    panel.grid = element_blank(),\n    \n    legend.position = \"bottom\",\n    legend.title = element_text(size= 9),\n    legend.margin=margin(grid::unit(0,\"cm\")),\n    legend.key.width=grid::unit(2,\"cm\"),\n    legend.key.height=grid::unit(0.2,\"cm\")\n)\n\nday_weekp\n\n\n\n\n\nSo, from the above graph, its clear that Maximum no of orders are placed between 10:00AM and 5:00PM on Sunday and Monday.\nActions: Develop strategies to increase sales during the quietest days of the week:\n\nOffer discounts on certain items.\nOffer free delivery with orders over a specific dollar amount.\n\nPositive note: Customers can shop on a Wednesday or Thursday, and most likely, they will never encounter “out of stock” items or delivery/pick delays.\n\n\nShow the code\ndata%>%\n  group_by(days_since_prior_order) %>%\n  dplyr::summarise(torders = n())%>%\n  mutate(color= ifelse(torders>100000, \"#CC5500\", \"gray\"))%>%\n\n  ggplot(aes(x = days_since_prior_order, y= torders, fill= color)) + \n  geom_col(show.legend = FALSE) +\n  scale_x_continuous(breaks = seq(0, 30, 5))+\n  scale_y_continuous(labels = scales::comma)+\n  scale_fill_manual(\"\", values = c(\"#CC5500\", \"gray\"))+\n  labs(x= \"Days Since Prior Order\",\n       y= \"Number of Orders\",\n       title = \"How Many Days Do Customer Wait to Place a New Order?\")+\n  \n ggpubr::theme_pubclean()+\n theme(plot.title = element_text(size =10, hjust = 0.50, vjust = 1),\n           axis.text = element_text(size= 10)) \n\n\n\n\n\nMost customers wait approximately 30 days to place their next order, followed by another majority of customers who wait seven days to make their next purchase.\n\nBestsellers Products\n\n\nShow the code\ntype <- data   %>%\n    group_by(product_id)%>% \n    dplyr::summarize(count = n()) %>% \n    top_n(20, wt = count) %>%\n    left_join(select(products, product_id, product_name, category), by=\"product_id\") %>%\n    arrange(desc(count))\n\n \n\nbest <- type %>% \nggplot(aes(x=reorder(product_name,count), y=count, color= category, text= paste0(product_name, \", Total Orders:\", count)))+    \n  geom_point(size= 2)+\n    geom_segment(aes(x=reorder(product_name,count), \n                     xend=reorder(product_name,count), \n                     y=0, \n                     yend=count), size=0.8)+\n  \n    scale_y_continuous(labels = scales::comma) +\n  \n      labs(title=\"Bestsellers Products\",\n           subtitle = \"Organic vs Non-Organic\",\n           y=\"\", \n           x=\"\", \n           legend = \"\")+\n     scale_color_manual(\"\", values = c(\"#CC5500\", \"#0AAD0A\"))+\n\n      theme(\n       axis.text.x= element_text( size= 7),\n       axis.text.y= element_text( size= 8),\n\n       panel.grid.major.x = element_blank(),\n       panel.grid.major.y = element_blank(),\n       panel.grid.minor.y = element_blank(),\n       panel.grid = element_line(color = \"#e5e5e5\"))+\n  \n     ggpubr::theme_pubclean()+\n     coord_flip()\n\nggplotly(best, tooltip = \"text\")\n\n\n\n\n\n\nThe highest ordered products are Banana, Bag of Organic Bananas, Organic Strawberries and Organic Baby Spinach. So to increase the sale of Strawberries the retailer can put it near the Bananas.\n\n\nShow the code\nProd_portf <- data %>% \n  group_by(product_id) %>% \n  dplyr::summarize(count=n()) %>% \n  left_join(products,by=\"product_id\") %>% \n  ungroup() %>% \n  group_by(department_id,aisle_id) %>% \n  dplyr::summarize(sumcount = sum(count)) %>% \n  left_join(df, by = c(\"department_id\", \"aisle_id\")) %>% \n  mutate(onesize = 1)\n\n\n## Treemap\n\np <-  treemap(Prod_portf,\n              index=c(\"department\",\"aisle\"),\n        vSize=\"n\",\n        vColor= \"department\",\n        type=\"index\",\n        \n        #Main\n        palette= \"Set3\",\n        title=\"Product Portfolio\",\n        sortID=\"-sumcount\")\n\n\n\n\nShow the code\nd3tree2( p,  rootname = \"Portfolio\" )"
  },
  {
    "objectID": "posts/Instacart/index.html",
    "href": "posts/Instacart/index.html",
    "title": "Instacart",
    "section": "",
    "text": "The data analyzed came for kaggle, https://www.kaggle.com/c/instacart-market-basket-analysis/data. The dataset is anonymized and contains a sample of over 3 million grocery orders from more than 200,000 Instacart users\nOnce the dataset is downloaded, it weighs 200.7 MB in zip format. Once unzipped, six files appear:\n\ndepartments.csv: Collect name and id for different departments.\naisle.csv: That collects the corridors and the different sections.\nproducts.csv: Collect all the products that are for sale in the store.\norders.csv: Collect all the orders made by customers, or which is the same, all the shopping carts (Market_Basket).\norder_products_prior.csv: Collect the products that were purchased in an order and all the customer’s purchase history throughout that year.\norder_products_train.csv: Collect the products that were purchased in an order reflecting the last basket purchased by each customer.\n\nFor this analysis, we will use the order_products_train.csv, which offers a data sample of the order_products_prior.csv"
  },
  {
    "objectID": "posts/Instacart/index.html#prepare-and-analyze-the-data",
    "href": "posts/Instacart/index.html#prepare-and-analyze-the-data",
    "title": "Instacart",
    "section": "Prepare and Analyze the Data",
    "text": "Prepare and Analyze the Data\nLoad the data: Departments, order_products, orders, products and aisles\n\n\nShow the code\ndepartments <- read.csv(\"C:/Users/karol/Desktop/DATA/INSTA/departments.csv\")\norder_products <- read.csv(\"C:/Users/karol/Desktop/DATA/INSTA/order_products__train.csv\")\norders <- read.csv(\"C:/Users/karol/Desktop/DATA/INSTA/orders.csv\")\nproducts <- read.csv(\"C:/Users/karol/Desktop/DATA/INSTA/products.csv\")\naisles <- read.csv(\"C:/Users/karol/Desktop/DATA/INSTA/aisles.csv\")\n\n\n\nDepartments\n\n\nShow the code\nglimpse(departments)\n\n\nRows: 21\nColumns: 2\n$ department_id <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ department    <chr> \"frozen\", \"other\", \"bakery\", \"produce\", \"alcohol\", \"inte…\n\n\n\n\nOrder Products\n\n\nShow the code\nglimpse(order_products)\n\n\nRows: 1,384,617\nColumns: 4\n$ order_id          <int> 1, 1, 1, 1, 1, 1, 1, 1, 36, 36, 36, 36, 36, 36, 36, …\n$ product_id        <int> 49302, 11109, 10246, 49683, 43633, 13176, 47209, 220…\n$ add_to_cart_order <int> 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2…\n$ reordered         <int> 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0…\n\n\n\n\nOrders\n\n\nShow the code\nglimpse(orders)\n\n\nRows: 3,421,083\nColumns: 7\n$ order_id               <int> 2539329, 2398795, 473747, 2254736, 431534, 3367…\n$ user_id                <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2,…\n$ eval_set               <chr> \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"p…\n$ order_number           <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1, 2, 3, 4, …\n$ order_dow              <int> 2, 3, 3, 4, 4, 2, 1, 1, 1, 4, 4, 2, 5, 1, 2, 3,…\n$ order_hour_of_day      <int> 8, 7, 12, 7, 15, 7, 9, 14, 16, 8, 8, 11, 10, 10…\n$ days_since_prior_order <dbl> NA, 15, 21, 29, 28, 19, 20, 14, 0, 30, 14, NA, …\n\n\n\n\nProducts\n\n\nShow the code\nglimpse(products)\n\n\nRows: 49,688\nColumns: 4\n$ product_id    <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ product_name  <chr> \"Chocolate Sandwich Cookies\", \"All-Seasons Salt\", \"Robus…\n$ aisle_id      <int> 61, 104, 94, 38, 5, 11, 98, 116, 120, 115, 31, 119, 11, …\n$ department_id <int> 19, 13, 7, 1, 13, 11, 7, 1, 16, 7, 7, 1, 11, 17, 18, 19,…\n\n\n\n\nAisles\n\n\nShow the code\nglimpse(aisles)\n\n\nRows: 134\nColumns: 2\n$ aisle_id <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ aisle    <chr> \"prepared soups salads\", \"specialty cheeses\", \"energy granola…\n\n\n\nCombining and Transforming the data\n\n\nShow the code\norders$order_hour_of_day <- as.numeric(orders$order_hour_of_day)\n\nproducts <- products%>% mutate(category =  ifelse(grepl(\"Organic\", products$product_name), \"Organic\",  \"Non-organic\"))\ndf <- products %>% group_by(department_id, aisle_id, product_id, product_name, category) %>% dplyr::summarize(n=n())\n\n\ndf <- df %>% left_join(departments,by=\"department_id\")\ndf<-  df %>% left_join(aisles,by=\"aisle_id\")\ndata <- merge(x= order_products,y= df, by= \"product_id\")\ndata <- merge(x= data, y= orders, by= \"order_id\")\n\n\nproducts <- products %>% mutate(product_name = as.factor(product_name))\n\naisles <- aisles %>% mutate(aisle = as.factor(aisle))\ndepartments <- departments %>% mutate(department = as.factor(department))\ndata <- data %>% mutate(product_name = as.factor(product_name))\ndata <- data %>% mutate(order_id = as.character(order_id))\ndata <- data %>% mutate(add_to_cart_order = as.factor(add_to_cart_order))\ndata <- data %>% mutate(reordered = as.factor(reordered))\n\n\n\n\nShow the code\nstr(data)\n\n\n'data.frame':   1384617 obs. of  17 variables:\n $ order_id              : chr  \"1\" \"1\" \"1\" \"1\" ...\n $ product_id            : int  13176 49302 22035 11109 47209 49683 43633 10246 43086 39612 ...\n $ add_to_cart_order     : Factor w/ 80 levels \"1\",\"2\",\"3\",\"4\",..: 6 1 8 2 7 4 5 3 4 1 ...\n $ reordered             : Factor w/ 2 levels \"0\",\"1\": 1 2 2 2 1 1 2 1 2 1 ...\n $ department_id         : int  4 16 16 16 4 4 15 4 4 16 ...\n $ aisle_id              : int  24 120 21 108 24 83 95 83 123 2 ...\n $ product_name          : Factor w/ 39123 levels \"#2 Coffee Filters\",..: 2635 4507 25657 22359 23761 9089 18248 22851 34372 14425 ...\n $ category              : chr  \"Organic\" \"Non-organic\" \"Organic\" \"Organic\" ...\n $ n                     : int  1 1 1 1 1 1 1 1 1 1 ...\n $ department            : chr  \"produce\" \"dairy eggs\" \"dairy eggs\" \"dairy eggs\" ...\n $ aisle                 : chr  \"fresh fruits\" \"yogurt\" \"packaged cheese\" \"other creams cheeses\" ...\n $ user_id               : int  112108 112108 112108 112108 112108 112108 112108 112108 79431 79431 ...\n $ eval_set              : chr  \"train\" \"train\" \"train\" \"train\" ...\n $ order_number          : int  4 4 4 4 4 4 4 4 23 23 ...\n $ order_dow             : int  4 4 4 4 4 4 4 4 6 6 ...\n $ order_hour_of_day     : num  10 10 10 10 10 10 10 10 18 18 ...\n $ days_since_prior_order: num  9 9 9 9 9 9 9 9 30 30 ...\n\n\n\n\n\nData Exploration\nMaximum number of orders are placed between 9:00am and 4:00pm on Sunday and Monday. There is also a big number of orders during Friday and Saturday.\n\n\nShow the code\nday_week <- orders %>%\n    mutate(day = as.factor(order_dow)) %>%\n    mutate(hour = as.factor(order_hour_of_day)) %>%\n    group_by(day,hour) %>%\n    dplyr::summarise(count = n()) %>%\n    arrange(desc(count))\n\nday_weekp <-day_week %>%\n    ggplot(aes(x=day, y=hour))+\n    geom_tile(aes(fill=count), colour = \"white\") + \n  \n    scale_fill_gradient(name= \"Number of\\nOrders\", \n                        low = \"#FFF5EE\",\n                        high = \"#CC5500\")+\n    scale_x_discrete( position = \"top\",\n                    breaks = c(\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\"),\n                    label = c(\"Sunday\", \"Monday\", \"Tuesday\",\n                              \"Wednesday\",\"Thursday\", \"Friday\", \"Saturday\"),\n                    expand=c(0,0))+\n    scale_y_discrete( \n                    breaks = c(\"0\", \"6\", \"12\", \"18\", \"23\"),\n                    label = c(\"12am\", \"6am\", \"12pm\", \"6pm\", \"11pm\"),\n                    expand=c(0,0))+\n  \n    labs(title=\"Which Day and What Time Do Customers Order the Most?\",\n            x=\"\", \n            y=\"\")+\n  \n    ggpubr::theme_pubclean()+\n    theme(\n      \n    axis.line=element_blank(),                                               \n    axis.ticks=element_line(size=0.4),\n    axis.text = element_text(size= 10),\n\n    plot.background=element_blank(),         \n    plot.title = element_text(size =10, hjust = 0.50, vjust = 1),\n    plot.caption = element_text(hjust = 0, size = 5, \n                                margin = unit(c(0.5, 0.5, 0.5, 0.5), \"cm\")),\n\n    \n    panel.grid = element_blank(),\n    \n    legend.position = \"bottom\",\n    legend.title = element_text(size= 9),\n    legend.margin=margin(grid::unit(0,\"cm\")),\n    legend.key.width=grid::unit(2,\"cm\"),\n    legend.key.height=grid::unit(0.2,\"cm\")\n)\n\nday_weekp\n\n\n\n\n\nSo, from the above graph, its clear that Maximum no of orders are placed between 10:00AM and 5:00PM on Sunday and Monday.\nActions: Develop strategies to increase sales during the quietest days of the week:\n\nOffer discounts on certain items.\nOffer free delivery with orders over a specific dollar amount.\n\nPositive note: Customers can shop on a Wednesday or Thursday, and most likely, they will never encounter “out of stock” items or delivery/pick delays.\n\n\nShow the code\ndata%>%\n  group_by(days_since_prior_order) %>%\n  dplyr::summarise(torders = n())%>%\n  mutate(color= ifelse(torders>100000, \"#CC5500\", \"gray\"))%>%\n\n  ggplot(aes(x = days_since_prior_order, y= torders, fill= color)) + \n  geom_col(show.legend = FALSE) +\n  scale_x_continuous(breaks = seq(0, 30, 5))+\n  scale_y_continuous(labels = scales::comma)+\n  scale_fill_manual(\"\", values = c(\"#CC5500\", \"gray\"))+\n  labs(x= \"Days Since Prior Order\",\n       y= \"Number of Orders\",\n       title = \"How Many Days Do Customer Wait to Place a New Order?\")+\n  \n ggpubr::theme_pubclean()+\n theme(plot.title = element_text(size =10, hjust = 0.50, vjust = 1),\n           axis.text = element_text(size= 10)) \n\n\n\n\n\nMost customers wait approximately 30 days to place their next order, followed by another majority of customers who wait seven days to make their next purchase.\n\nBestsellers Products\n\n\nShow the code\ntype <- data   %>%\n    group_by(product_id)%>% \n    dplyr::summarize(count = n()) %>% \n    top_n(20, wt = count) %>%\n    left_join(select(products, product_id, product_name, category), by=\"product_id\") %>%\n    arrange(desc(count))\n\n \n\nbest <- type %>% \nggplot(aes(x=reorder(product_name,count), y=count, color= category, text= paste0(product_name, \", Total Orders:\", count)))+    \n  geom_point(size= 2)+\n    geom_segment(aes(x=reorder(product_name,count), \n                     xend=reorder(product_name,count), \n                     y=0, \n                     yend=count), size=0.8)+\n  \n    scale_y_continuous(labels = scales::comma) +\n  \n      labs(title=\"Bestsellers Products\",\n           subtitle = \"Organic vs Non-Organic\",\n           y=\"\", \n           x=\"\", \n           legend = \"\")+\n     scale_color_manual(\"\", values = c(\"#CC5500\", \"#0AAD0A\"))+\n\n      theme(\n       axis.text.x= element_text( size= 7),\n       axis.text.y= element_text( size= 8),\n\n       panel.grid.major.x = element_blank(),\n       panel.grid.major.y = element_blank(),\n       panel.grid.minor.y = element_blank(),\n       panel.grid = element_line(color = \"#e5e5e5\"))+\n  \n     ggpubr::theme_pubclean()+\n     coord_flip()\n\nggplotly(best, tooltip = \"text\")\n\n\n\n\n\n\nThe highest ordered products are Banana, Bag of Organic Bananas, Organic Strawberries and Organic Baby Spinach. So to increase the sale of Strawberries the retailer can put it near the Bananas.\n\n\nShow the code\nProd_portf <- data %>% \n  group_by(product_id) %>% \n  dplyr::summarize(count=n()) %>% \n  left_join(products,by=\"product_id\") %>% \n  ungroup() %>% \n  group_by(department_id,aisle_id) %>% \n  dplyr::summarize(sumcount = sum(count)) %>% \n  left_join(df, by = c(\"department_id\", \"aisle_id\")) %>% \n  mutate(onesize = 1)\n\n\n## Treemap\n\np <-  treemap(Prod_portf,\n              index=c(\"department\",\"aisle\"),\n        vSize=\"n\",\n        vColor= \"department\",\n        type=\"index\",\n        \n        #Main\n        palette= \"Set3\",\n        title=\"Product Portfolio\",\n        sortID=\"-sumcount\")\n\n\n\n\nShow the code\nd3tree2( p,  rootname = \"Portfolio\" )"
  },
  {
    "objectID": "posts/Regression/Analyzing Employee Turnover.html",
    "href": "posts/Regression/Analyzing Employee Turnover.html",
    "title": "Analyzing Employee Turnover",
    "section": "",
    "text": "You work for the human capital department of a large corporation. The Board is worried about the relatively high turnover, and your team must look into ways to reduce the number of employees leaving the company. The team needs to understand better the situation, which employees are more likely to leave, and why. Once it is clear what variables impact employee churn, you can present your findings along with your ideas on how to attack the problem.\n\n\nCreate a report that covers the following:\n\nWhich department has the highest employee turnover? Which one has the lowest?\nInvestigate which variables seem to be better predictors of employee departure.\nWhat recommendations would you make regarding ways to reduce employee turnover?"
  },
  {
    "objectID": "posts/Regression/Analyzing Employee Turnover.html#import-libraries",
    "href": "posts/Regression/Analyzing Employee Turnover.html#import-libraries",
    "title": "Analyzing Employee Turnover",
    "section": "2. Import Libraries",
    "text": "2. Import Libraries\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(skimr)\nlibrary(janitor)\nlibrary(knitr)\nlibrary(radiant)\nlibrary(colorspace)\nlibrary(gridExtra)\nlibrary(jtools)\nlibrary(dplyr)\nlibrary(MASS)"
  },
  {
    "objectID": "posts/Regression/Analyzing Employee Turnover.html#prepare-and-analyze-the-data",
    "href": "posts/Regression/Analyzing Employee Turnover.html#prepare-and-analyze-the-data",
    "title": "Analyzing Employee Turnover",
    "section": "3. Prepare and Analyze the Data",
    "text": "3. Prepare and Analyze the Data\nThe department has assembled data on almost 10,000 employees. The team used information from exit interviews, performance reviews, and employee records.\n\n\n\nThe variables are defined as follow:\n\n“department” - the department the employee belongs to.\n“promoted” - 1 if the employee was promoted in the previous 24 months, 0 otherwise.\n“review” - the composite score the employee received in their last evaluation.\n“projects” - how many projects the employee is involved in.\n“salary” - for confidentiality reasons, salary comes in three tiers: low, medium, high.\n“tenure” - how many years the employee has been at the company.\n“satisfaction” - a measure of employee satisfaction from surveys.\n“bonus” - 1 if the employee received a bonus in the previous 24 months, 0 otherwise.\n“avg_hrs_month” - the average hours the employee worked in a month.\n“left” - “yes” if the employee ended up leaving, “no” otherwise.\n\n\n\n\nData summary\n\n\nName\nempl_turnover\n\n\nNumber of rows\n9540\n\n\nNumber of columns\n10\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ndepartment\n0\n1\n2\n11\n0\n10\n0\n\n\nsalary\n0\n1\n3\n6\n0\n3\n0\n\n\nleft\n0\n1\n2\n3\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\npromoted\n0\n1\n0.03\n0.17\n0.00\n0.00\n0.00\n0.00\n1.00\n▇▁▁▁▁\n\n\nreview\n0\n1\n0.65\n0.09\n0.31\n0.59\n0.65\n0.71\n1.00\n▁▃▇▃▁\n\n\nprojects\n0\n1\n3.27\n0.58\n2.00\n3.00\n3.00\n4.00\n5.00\n▁▇▁▅▁\n\n\ntenure\n0\n1\n6.56\n1.42\n2.00\n5.00\n7.00\n8.00\n12.00\n▁▇▇▂▁\n\n\nsatisfaction\n0\n1\n0.50\n0.16\n0.00\n0.39\n0.50\n0.62\n1.00\n▁▅▇▅▁\n\n\nbonus\n0\n1\n0.21\n0.41\n0.00\n0.00\n0.00\n0.00\n1.00\n▇▁▁▁▂\n\n\navg_hrs_month\n0\n1\n184.66\n4.14\n171.37\n181.47\n184.63\n187.73\n200.86\n▁▆▇▂▁\n\n\n\n\n\n\nThere is no missing data in the data set.\nEmployees are involved between 2 to 5 projects\nEmployees have been at the company between 2 to 12 years, with an average of 6.5 years\nThe average satisfaction rate in 50.41% for all employees\nThe average worked hours per month ranged from 171.37 to 200.86 hours\nThere are some data types that need to be changed. For example, “left” is a character variable. To convert it into a quantity that takes values of zero and one, I’ll convert it into a variable of type factor with two levels: No and Yes. Later, I will use as.numeric() to convert the observations to a number, one or two. I then subtract one to get a variable that takes values zero or one and stores it as left.Numeric\n\n\n\nShow the code\nempl_turnover$department <- as.factor(empl_turnover$department)\nempl_turnover$left<- as.factor(empl_turnover$left)\nempl_turnover$promoted<- as.factor(empl_turnover$promoted)\nempl_turnover$bonus<- as.factor(empl_turnover$bonus)\nempl_turnover$salary<- factor(empl_turnover$salary, levels = c(\"low\", \"medium\", \"high\"))\nempl_turnover$left.Numeric <- as.numeric(as.factor(empl_turnover$left))-1\n\n\nglimpse(empl_turnover)\n\n\nRows: 9,540\nColumns: 11\n$ department    <fct> operations, operations, support, logistics, sales, IT, a…\n$ promoted      <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ review        <dbl> 0.5775687, 0.7518997, 0.7225484, 0.6751583, 0.6762032, 0…\n$ projects      <int> 3, 3, 3, 4, 3, 2, 4, 4, 4, 3, 4, 3, 3, 3, 3, 3, 4, 4, 3,…\n$ salary        <fct> low, medium, medium, high, high, medium, high, medium, l…\n$ tenure        <dbl> 5, 6, 6, 8, 5, 5, 5, 7, 6, 6, 5, 5, 6, 5, 6, 6, 6, 5, 6,…\n$ satisfaction  <dbl> 0.6267590, 0.4436790, 0.4468232, 0.4401387, 0.5776074, 0…\n$ bonus         <fct> 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,…\n$ avg_hrs_month <dbl> 180.8661, 182.7081, 184.4161, 188.7075, 179.8211, 178.84…\n$ left          <fct> no, no, no, no, no, no, no, no, no, no, no, no, no, no, …\n$ left.Numeric  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n\n\n\nTurnover\nNumber of employees that left the company:\nThe overall attrition rate in the company is 29.2%, which means that 2,784 of 9,540 employees have left the company over the past 24 months.\n\n\nShow the code\nempl_turnover_left <- single_prop(empl_turnover, var = \"left\", lev = \"yes\")\nsummary(empl_turnover_left)\n\n\nSingle proportion test (binomial exact)\nData      : empl_turnover \nVariable  : left \nLevel     : yes in left \nConfidence: 0.95 \nNull hyp. : the proportion of yes in left = 0.5 \nAlt. hyp. : the proportion of yes in left not equal to 0.5 \n\n     p    ns     n n_missing    sd    se    me\n 0.292 2,784 9,540         0 0.455 0.005 0.009\n\n   diff    ns p.value  2.5% 97.5%    \n -0.208 2,784  < .001 0.283 0.301 ***\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nAre the employees leaving the different departments at the same rate?\n\nThe data shows that the IT department has the highest employee turnover rate, followed by logistics and retail. Finance has the lowest rate.\n\n\n\nShow the code\nempl_turnover_prop <- empl_turnover %>% \n  tabyl(department, left) %>%\n  adorn_percentages(\"row\") %>%\n  mutate(Perc_empl_left = paste0(round(yes * 100),\"%\"))\n\nkable(empl_turnover_prop,  caption = \"Department vs Attrition\")\n\n\n\nDepartment vs Attrition\n\n\ndepartment\nno\nyes\nPerc_empl_left\n\n\n\n\nadmin\n0.7186761\n0.2813239\n28%\n\n\nengineering\n0.7117414\n0.2882586\n29%\n\n\nfinance\n0.7313433\n0.2686567\n27%\n\n\nIT\n0.6910112\n0.3089888\n31%\n\n\nlogistics\n0.6916667\n0.3083333\n31%\n\n\nmarketing\n0.6970075\n0.3029925\n30%\n\n\noperations\n0.7135348\n0.2864652\n29%\n\n\nretail\n0.6943543\n0.3056457\n31%\n\n\nsales\n0.7148168\n0.2851832\n29%\n\n\nsupport\n0.7115646\n0.2884354\n29%\n\n\n\n\n\n\n\nShow the code\nempl_turnover$reordept <-reorder(empl_turnover$department, empl_turnover$left, \n                                 FUN=function(x) mean(as.numeric(x)))\n\n\nplot_depart <- empl_turnover %>%\nggplot(aes(x = reordept, fill = left)) +\ngeom_bar(position = \"fill\")+\nscale_fill_manual(values=c(\"gray\", \"#2166AC\"))+\nlabs(title = \"Turnover Rate by Department\",\n      y= \" \",\n      x= \" \") +\ncoord_flip() +\n ggpubr::theme_pubclean()+\ntheme(\n    plot.title = element_text(size =9, face = \"bold\", hjust = 0.55),\n    legend.position=\"bottom\")\n\nplot_depart\n\n\n\n\n\n\n\nAttrition vs Years at the company\nThe majority of employees that left the organization, had been working for the company between 5 to 8 years, and the proportion steadily declined.\nWhat does it mean for the organization? Well,\n\n\nShow the code\n### Tenure vs Turnover\n\n\nempl_turnover %>%\ngroup_by(tenure, left)%>%\nggplot(aes(x = tenure, fill = left)) +\ngeom_histogram(bins = 30L) +\n\nscale_fill_manual(values=c(\"gray\", \"#2166AC\"))+\n\n ggpubr::theme_pubclean()+\n\n\n  labs( x= \"Years at the Company\",\n        y= \"Number of Employees\",\n        title = \"Attrition vs Number of Years Working at the Company\")+\n\ntheme(plot.title = element_text(size =12, face = \"bold\", hjust = 0.45),\nlegend.position=\"bottom\")\n\n\n\n\n\n\n\nDo the number of projects employees are involved in and the number of hours per month worked matter in their retention?\nYes, there is a high attrition rate in employees that: - Are involved in less than three projects - Tend to work ~184 hours per month (assuming a five days work week- 8 hours each)\n\n\nShow the code\n## Projects vs Turnover\n\nprojects_turnover <- compare_props(\n  empl_turnover, \n  var1 = \"projects\", \n  var2 = \"left\", \n  levs = \"yes\")\n\nplot_proj <- plot(projects_turnover, plots = \"bar\", custom = TRUE)+ \n             labs(title = \"Attrition vs Number of Projects\",\n                      y = \" Percentage of Employees that Left\",\n                      x = \"Number of Projects Involved in\") +\n              scale_fill_discrete_diverging(\"Blue-Red\")+\n              ggpubr::theme_pubclean()+\n              theme( plot.title = element_text(size =10, \n                                               face = \"bold\", \n                                               hjust = 0.55),\n                     legend.position=\"none\")\n\n## Avg hours vs Turnover\n\nplot_avg_hrs_month <- empl_turnover %>%\n    ggplot() +\n    aes() +\n    geom_histogram(aes(y = ..density.., x = avg_hrs_month, fill = left), bins=30, )+\n    \n    facet_wrap(~ left) +   \n    scale_y_continuous(labels = scales::percent)+\n\n             labs(title = \"Attrition vs Avg Hours Worked\",\n                      y = \"Employment Status (Left)\",\n                      x = \"Number of hours worked\") +\n              scale_fill_manual(values=c(\"gray\", \"#2166AC\"))+ \n              ggpubr::theme_pubclean()+\n              theme( plot.title = element_text(size =10, face = \"bold\", hjust = 0.55),\n                     legend.position=\"none\")\n\n\n\n\n\n\n\n\n\nAttrition vs Promotion, Bonus and Salary\nMost employees are in the medium salary tier, with the rest evenly split between low and high salaries. However, this variable is no significant impact on the turnover status of the employee. Likewise, whether or not an employee received a bonus is not statistically significant on the decision to stay or leave the company.\nThe promotion variable shows a higher proportion of employees had stayed with the organization if they had received a promotion.\n\n\n\n\n\n\n\n\n\n\nEmployee Satisfaction and Review score\n\nEmployees tend to have lower satisfaction ratings as performance scores increase across employees. As the chart below shows, this feature is more appreciable for employees who have left the company in the last 24 months.\n\n\n\nShow the code\nplot_rev_sat_left<- empl_turnover %>% \n  ggplot(aes(x=review,y= satisfaction, color=left)) +\n  geom_point(alpha=0.16) + \n  geom_smooth(method=lm,se=FALSE)+\n  facet_wrap(~department, ncol=4)+\n   ggpubr::theme_pubclean()+\n   labs (x = \"Review\", \n         y = \"Satisfaction Level\",\n         title= \"\") +\n  theme(\n          strip.background= element_rect(fill= \"white\", linetype = \"blank\"),\n          strip.text = element_text(color= \"black\", face= \"bold\"),\n          strip.text.x = element_text(face = \"bold\", size= 10),\n          \n          plot.title = element_text(size =9, face = \"bold\", hjust = 0.55),\n          plot.title.position = \"plot\")+\n          scale_color_manual(values=c(\"gray\", \"#2166AC\"))\n\n\n\nplot_rev_sat_left"
  },
  {
    "objectID": "posts/Regression/Analyzing Employee Turnover.html#the-model",
    "href": "posts/Regression/Analyzing Employee Turnover.html#the-model",
    "title": "Analyzing Employee Turnover",
    "section": "4. The Model",
    "text": "4. The Model\n\nA Scaled Coefficient Plot\nThe graph below shows that not all the predictors are important in deciding to leave the company. Review, satisfaction, promoted and avg_hrs_month, by conventional standards, have a very low probability of no relationship/zero slopes.\n\n\nShow the code\nempl_turnover %>%\n    mutate(review = scale(review), satisfaction = scale(satisfaction), tenure = scale(tenure),projects = scale(projects), avg_hrs_month = scale(avg_hrs_month)) %>%\n  \n    glm(left ~ department+ review+ satisfaction+ avg_hrs_month+ promoted+ tenure+ promoted+ projects+ salary+ bonus,\n        family = binomial(link = \"probit\"), data = .) %>%\n    plot_summs(., inner_ci_level = 0.95)\n\n\n\n\n\n\n\nLogistic Regression\nFor my model I will use the following variables: promoted, review, projects, satisfaction, and average hours worked. This decision was made based on an stepwise regression model (using both forward selection and backward elimination) where all the variables were included and the once with low colinearity were eliminated.\n\n\nShow the code\nempl_tur<- empl_turnover %>% dplyr:::select(c(-reordept, -left.Numeric))\n\n\n\n\nShow the code\nfull.model <- glm(left~ department+ promoted+ review+ projects+\nsalary+ tenure+ satisfaction+ bonus+ avg_hrs_month, \ndata = empl_tur, family = binomial)\n\nsummary(full.model)\n\n\n\nCall:\nglm(formula = left ~ department + promoted + review + projects + \n    salary + tenure + satisfaction + bonus + avg_hrs_month, family = binomial, \n    data = empl_tur)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.4381  -0.8205  -0.6034   1.0706   2.7779  \n\nCoefficients:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)           -21.493059   4.739307  -4.535 5.76e-06 ***\ndepartmentengineering   0.010344   0.130062   0.080 0.936608    \ndepartmentfinance      -0.070328   0.165088  -0.426 0.670107    \ndepartmentIT            0.121550   0.168377   0.722 0.470360    \ndepartmentlogistics     0.098104   0.167795   0.585 0.558773    \ndepartmentmarketing     0.043406   0.141465   0.307 0.758972    \ndepartmentoperations   -0.028534   0.129996  -0.219 0.826263    \ndepartmentretail        0.114473   0.129461   0.884 0.376575    \ndepartmentsales        -0.005853   0.127297  -0.046 0.963328    \ndepartmentsupport       0.024313   0.144010   0.169 0.865934    \npromotedYes            -0.558972   0.156892  -3.563 0.000367 ***\nreview                 11.160858   0.363223  30.727  < 2e-16 ***\nprojects               -0.067532   0.041581  -1.624 0.104350    \nsalarymedium            0.075272   0.069816   1.078 0.280970    \nsalaryhigh              0.018895   0.087327   0.216 0.828700    \ntenure                 -0.011131   0.082660  -0.135 0.892880    \nsatisfaction            2.457897   0.186556  13.175  < 2e-16 ***\nbonusYes               -0.057958   0.059113  -0.980 0.326853    \navg_hrs_month           0.066040   0.028298   2.334 0.019609 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 11520  on 9539  degrees of freedom\nResidual deviance: 10337  on 9521  degrees of freedom\nAIC: 10375\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\nLet’s split the data\n\n\nShow the code\nset.seed(123)\ndata_split <- initial_split(empl_tur, prop = 3/4)\n\ntrain.data <- training(data_split)\n\ntest.data  <- testing(data_split)\n\n\n\n\nComputing stepwise logistique regression\n\n\nShow the code\n# Fit the model\n\nmodel <- glm(left ~ department+ promoted+ review+ projects+\nsalary+ tenure+ satisfaction+ bonus+ avg_hrs_month,\ndata = train.data, family = binomial) %>%\n  stepAIC(trace = FALSE)\n\n# Summarize the final selected model\nsummary(model)\n\n\n\nCall:\nglm(formula = left ~ promoted + review + satisfaction + bonus + \n    avg_hrs_month, family = binomial, data = train.data)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.0471  -0.8148  -0.5930   1.0487   2.7958  \n\nCoefficients:\n                Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   -20.765742   1.441891 -14.402  < 2e-16 ***\npromotedYes    -0.586594   0.178620  -3.284  0.00102 ** \nreview         11.655310   0.428243  27.217  < 2e-16 ***\nsatisfaction    2.680873   0.219774  12.198  < 2e-16 ***\nbonusYes       -0.131276   0.069554  -1.887  0.05911 .  \navg_hrs_month   0.058488   0.006937   8.431  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 8595.3  on 7154  degrees of freedom\nResidual deviance: 7660.6  on 7149  degrees of freedom\nAIC: 7672.6\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\nPerform stepwise variable selection\nSelect the most contributive variables:\n\n\nShow the code\nmodel2 <- glm(formula = left ~ promoted + review + satisfaction + bonus + tenure +  avg_hrs_month, family = binomial, data = train.data)\n\ncoef(model2)\n\n\n  (Intercept)   promotedYes        review  satisfaction      bonusYes \n -24.92708321   -0.58724188   11.66591046    2.67842602   -0.13178813 \n       tenure avg_hrs_month \n  -0.07543137    0.08367092 \n\n\nShow the code\nmodel_diagnostics2 <- LogisticDx::gof(model2, plotROC = TRUE)\n\n\n\n\n\nThe accuracy of this model is 74%, that is - the model about 74% of the time can correctly classify whether an individual will leave or stay.\nFurther work can explore other classification models (such as decision trees) to improve performance for determining factors influencing an employee’s reason to leave. Improving prediction response can help identify the most at-risk staff."
  },
  {
    "objectID": "posts/Time-Series/TimeSeries.html",
    "href": "posts/Time-Series/TimeSeries.html",
    "title": "Time Series Project",
    "section": "",
    "text": "Show the code\nmetrofour <- read.csv(\"C:/Users/karol/Desktop/City_zhvi_bdrmcnt_4_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv\")\n\nstr(metrofour[,c(1:11)])\n\n\n'data.frame':   13513 obs. of  11 variables:\n $ RegionID   : int  6181 12447 39051 17426 6915 40326 13271 18959 54296 38128 ...\n $ SizeRank   : int  0 1 2 3 4 5 6 7 8 9 ...\n $ RegionName : chr  \"New York\" \"Los Angeles\" \"Houston\" \"Chicago\" ...\n $ RegionType : chr  \"city\" \"city\" \"city\" \"city\" ...\n $ StateName  : chr  \"NY\" \"CA\" \"TX\" \"IL\" ...\n $ State      : chr  \"NY\" \"CA\" \"TX\" \"IL\" ...\n $ Metro      : chr  \"New York-Newark-Jersey City, NY-NJ-PA\" \"Los Angeles-Long Beach-Anaheim, CA\" \"Houston-The Woodlands-Sugar Land, TX\" \"Chicago-Naperville-Elgin, IL-IN-WI\" ...\n $ CountyName : chr  \"Queens County\" \"Los Angeles County\" \"Harris County\" \"Cook County\" ...\n $ X2000.01.31: num  285211 302931 146651 181138 153807 ...\n $ X2000.02.29: num  287376 303230 146544 181616 154106 ...\n $ X2000.03.31: num  289205 304587 146194 182517 154357 ...\n\n\nWe have to make this dataset tidy. Tidy Data is a way of structuring data so that it can be easily understood by people and analyzed by machines.\nI need to remove the X at the beginning of the dates (X2000.01.31,X2000.02.29,…)\n\n\nShow the code\nnames(metrofour) <- sub(\"^X\", \"\", names(metrofour))\n\nstr(metrofour[,c(1:11)])\n\n\n'data.frame':   13513 obs. of  11 variables:\n $ RegionID  : int  6181 12447 39051 17426 6915 40326 13271 18959 54296 38128 ...\n $ SizeRank  : int  0 1 2 3 4 5 6 7 8 9 ...\n $ RegionName: chr  \"New York\" \"Los Angeles\" \"Houston\" \"Chicago\" ...\n $ RegionType: chr  \"city\" \"city\" \"city\" \"city\" ...\n $ StateName : chr  \"NY\" \"CA\" \"TX\" \"IL\" ...\n $ State     : chr  \"NY\" \"CA\" \"TX\" \"IL\" ...\n $ Metro     : chr  \"New York-Newark-Jersey City, NY-NJ-PA\" \"Los Angeles-Long Beach-Anaheim, CA\" \"Houston-The Woodlands-Sugar Land, TX\" \"Chicago-Naperville-Elgin, IL-IN-WI\" ...\n $ CountyName: chr  \"Queens County\" \"Los Angeles County\" \"Harris County\" \"Cook County\" ...\n $ 2000.01.31: num  285211 302931 146651 181138 153807 ...\n $ 2000.02.29: num  287376 303230 146544 181616 154106 ...\n $ 2000.03.31: num  289205 304587 146194 182517 154357 ...\n\n\n\n\nShow the code\nhouse_price <- metrofour %>% \n  pivot_longer(-c(RegionID, SizeRank, RegionName, RegionType, StateName, State, Metro, CountyName),\n    names_to = \"Monthly\",\n    values_to = \"Price\"\n  ) \nstr(metrofour[,c(1:11)])\n\n\n'data.frame':   13513 obs. of  11 variables:\n $ RegionID  : int  6181 12447 39051 17426 6915 40326 13271 18959 54296 38128 ...\n $ SizeRank  : int  0 1 2 3 4 5 6 7 8 9 ...\n $ RegionName: chr  \"New York\" \"Los Angeles\" \"Houston\" \"Chicago\" ...\n $ RegionType: chr  \"city\" \"city\" \"city\" \"city\" ...\n $ StateName : chr  \"NY\" \"CA\" \"TX\" \"IL\" ...\n $ State     : chr  \"NY\" \"CA\" \"TX\" \"IL\" ...\n $ Metro     : chr  \"New York-Newark-Jersey City, NY-NJ-PA\" \"Los Angeles-Long Beach-Anaheim, CA\" \"Houston-The Woodlands-Sugar Land, TX\" \"Chicago-Naperville-Elgin, IL-IN-WI\" ...\n $ CountyName: chr  \"Queens County\" \"Los Angeles County\" \"Harris County\" \"Cook County\" ...\n $ 2000.01.31: num  285211 302931 146651 181138 153807 ...\n $ 2000.02.29: num  287376 303230 146544 181616 154106 ...\n $ 2000.03.31: num  289205 304587 146194 182517 154357 ...\n\n\n\n\nShow the code\n#Converting the Date from factor to character\n\nhouse_clean <- house_price %>%\n            mutate(Monthly_parsed = as.Date(Monthly,\"%Y.%m.%d\"))\n\n\nhouse_clean[[\"Monthly\"]]<- as.character(house_clean$Monthly)\n\nhouse_price[[\"Monthly\"]]<- as.character(house_price $Monthly)\nsummary(house_clean)\n\n\n    RegionID         SizeRank      RegionName         RegionType       \n Min.   :  3300   Min.   :    0   Length:3702562     Length:3702562    \n 1st Qu.: 17364   1st Qu.: 3506   Class :character   Class :character  \n Median : 31949   Median : 7193   Mode  :character   Mode  :character  \n Mean   : 51588   Mean   : 8231                                        \n 3rd Qu.: 46308   3rd Qu.:11702                                        \n Max.   :827230   Max.   :28439                                        \n                                                                       \n  StateName            State              Metro            CountyName       \n Length:3702562     Length:3702562     Length:3702562     Length:3702562    \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n   Monthly              Price         Monthly_parsed      \n Length:3702562     Min.   :  18032   Min.   :2000-01-31  \n Class :character   1st Qu.: 172756   1st Qu.:2005-09-30  \n Mode  :character   Median : 244796   Median :2011-06-15  \n                    Mean   : 321468   Mean   :2011-06-15  \n                    3rd Qu.: 368862   3rd Qu.:2017-02-28  \n                    Max.   :8241271   Max.   :2022-10-31  \n                    NA's   :1195958                       \n\n\nWe see some missing values in the Price variable, but before I deal with those values, I will filter my data to the cities that I am interested the most\n\n\nShow the code\npdx_data <- house_clean %>%\n  dplyr:::filter(RegionID== 13373)  %>%\n  dplyr:::filter(Monthly_parsed >= \"2014-01-01\")\n\nsummary(pdx_data)\n\n\n    RegionID        SizeRank   RegionName         RegionType       \n Min.   :13373   Min.   :22   Length:106         Length:106        \n 1st Qu.:13373   1st Qu.:22   Class :character   Class :character  \n Median :13373   Median :22   Mode  :character   Mode  :character  \n Mean   :13373   Mean   :22                                        \n 3rd Qu.:13373   3rd Qu.:22                                        \n Max.   :13373   Max.   :22                                        \n  StateName            State              Metro            CountyName       \n Length:106         Length:106         Length:106         Length:106        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n   Monthly              Price        Monthly_parsed      \n Length:106         Min.   :411049   Min.   :2014-01-31  \n Class :character   1st Qu.:505802   1st Qu.:2016-04-07  \n Mode  :character   Median :564917   Median :2018-06-15  \n                    Mean   :562387   Mean   :2018-06-15  \n                    3rd Qu.:584219   3rd Qu.:2020-08-23  \n                    Max.   :759661   Max.   :2022-10-31  \n\n\nAfter filtering the data, we don’t have any missing values\n\n\nA time series can be recorded as a tsibble object in R. tsibble objects extend tidy data frames (tibble objects) by introducing temporal structure, and to do it, we need to declare key and index. In this case, the Monthly_parsed containing the data-time is the index and the RegionID is the key. Other columns can be considered as measured variables.\n\n\nShow the code\ntsb_pdx <- pdx_data %>%\n                   select(RegionName,RegionID, Monthly_parsed, Price)\n\ntsb_pref_pdx <-tsb_pdx%>%\n  as_tsibble(key= RegionName, index= Monthly_parsed)%>%\n                   index_by(year_month = ~ yearmonth(.))\n\ntsibble_pdx <-tsb_pref_pdx%>%\n  select(-RegionID)%>%\n  as_tsibble(key= RegionName, index= year_month)%>%\n  mutate(Prices = Price/1000)"
  },
  {
    "objectID": "posts/Time-Series/TimeSeries.html#data-visualization",
    "href": "posts/Time-Series/TimeSeries.html#data-visualization",
    "title": "Time Series Project",
    "section": "Data Visualization",
    "text": "Data Visualization\nTo visualize the data, I could use the autoplot() command, but I rather to create my graph with ggplot.\n\n\nShow the code\nplot_pdx_house <- tsibble_pdx %>%\n  ggplot(aes(x= year_month, y= Prices)) +\n  geom_line(size=1, color= \"darkgreen\")+\n   \n    labs(y=\"Price in Thousands of Dollars \", \n       x= \" \",\n       title=\" Four Bedroom House Prices in Portland, OR, 2012-2022 \",\n       caption = \"data:https://www.zillow.com/research/data\")+\n  scale_y_continuous(labels=scales::dollar_format())+\n  theme_minimal()\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nShow the code\nplot_pdx_house \n\n\n\n\n\nData is non- stationary, we can see a trend-cycle component in the graph above."
  },
  {
    "objectID": "posts/Time-Series/TimeSeries.html#determining-stationarity",
    "href": "posts/Time-Series/TimeSeries.html#determining-stationarity",
    "title": "Time Series Project",
    "section": "Determining Stationarity",
    "text": "Determining Stationarity\nIn our analysis, we use the Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test (Kwiatkowski et al., 1992). In this test, the null hypothesis is that the data are stationary, and we look for evidence that the null hypothesis is false. Consequently, small p-values (e.g., less than 0.05) suggest that differencing is required. The test can be computed using the unitroot_kpss() function.\n\n\nShow the code\ntsibble_pdx%>%\n  features(Prices, unitroot_kpss)\n\n\n# A tibble: 1 × 3\n  RegionName kpss_stat kpss_pvalue\n  <chr>          <dbl>       <dbl>\n1 Portland        1.95        0.01\n\n\nThe p-value is reported as 0.01 if it is less than 0.01, and as 0.1 if it is greater than 0.1. In this case, the test statistic (1.946) is bigger than the 1% critical value, so the p-value is less than 0.01, indicating that the null hypothesis is rejected. That is, the data are not stationary.\n\n\nShow the code\ntsibble_pdx %>% \n  features(Prices ,unitroot_ndiffs)\n\n\n# A tibble: 1 × 2\n  RegionName ndiffs\n  <chr>       <int>\n1 Portland        1\n\n\nAs we saw from the KPSS tests above, one difference (d) is required to make the tsibble_pdx data stationary."
  },
  {
    "objectID": "posts/Time-Series/TimeSeries.html#autocorrelation",
    "href": "posts/Time-Series/TimeSeries.html#autocorrelation",
    "title": "Time Series Project",
    "section": "Autocorrelation",
    "text": "Autocorrelation\n\n\nShow the code\ntsibble_pdx %>%\n  gg_tsdisplay(Prices,\n                     plot_type='partial')+\n       labs(y=\"Thousands of Dollars \", \n       x= \" \")\n\n\n\n\n\nACF does not drop quickly to zero, moreover the value is large and positive (almost 1 in this case). All these are signs of a non-stationary time series. Therefore it should be differenced to obtain a stationary series.\nPACF value r1 is almost 1. All other values ri,i >1 are small. This is a sign of a non stationary process that should be differenced in order to obtain a stationary series.\nThe data are clearly non-stationary, so we will first take a seasonal difference. The seasonally differenced data are shown below:\n\n\nShow the code\ntsibble_pdx %>%\n  gg_tsdisplay(difference(Prices, 12),\n               plot_type='partial', lag=36) +\n  labs(title=\"Seasonally differenced\", y=\"\")\n\n\nWarning: Removed 12 rows containing missing values (`geom_line()`).\n\n\nWarning: Removed 12 rows containing missing values (`geom_point()`).\n\n\n\n\n\nThese are also clearly non-stationary, so we take a further first difference\n\n\nShow the code\ntsibble_pdx %>%\n  gg_tsdisplay(difference(Prices, 12) %>% difference(),\n               plot_type='partial', lag=36) +\n  labs(title = \"Double differenced\", y=\"\")\n\n\nWarning: Removed 13 rows containing missing values (`geom_line()`).\n\n\nWarning: Removed 13 rows containing missing values (`geom_point()`).\n\n\n\n\n\nOur aim now is to find an appropriate ARIMA model based on the ACF and PACF shown in the Double Differenced graph."
  },
  {
    "objectID": "posts/Time-Series/TimeSeries.html#seasonal-arima-model",
    "href": "posts/Time-Series/TimeSeries.html#seasonal-arima-model",
    "title": "Time Series Project",
    "section": "Seasonal Arima Model",
    "text": "Seasonal Arima Model\n\n\nShow the code\nall_fit <- tsibble_pdx%>%\n  model(\n    arima212012 = ARIMA(Prices ~ pdq(2,1,2)+ PDQ(0,1,2)),\n    arima210011 = ARIMA(Prices ~ pdq(2,1,0)+ PDQ(0,1,1)),\n    stepwise = ARIMA(Prices),\n    search = ARIMA(Prices,stepwise=FALSE))\n\n\n\n\nShow the code\nall_fit %>% pivot_longer(!RegionName,\n            names_to = \"Model name\", \n            values_to = \"Orders\")\n\n\n# A mable: 4 x 3\n# Key:     RegionName, Model name [4]\n  RegionName `Model name`                             Orders\n  <chr>      <chr>                                   <model>\n1 Portland   arima212012           <ARIMA(2,1,2)(0,1,2)[12]>\n2 Portland   arima210011           <ARIMA(2,1,0)(0,1,1)[12]>\n3 Portland   stepwise                <ARIMA(3,1,2) w/ drift>\n4 Portland   search       <ARIMA(2,1,3)(0,0,1)[12] w/ drift>\n\n\n\n\nShow the code\nglance(all_fit) %>% arrange(AICc) %>% select(.model:BIC)\n\n\n# A tibble: 4 × 6\n  .model      sigma2 log_lik   AIC  AICc   BIC\n  <chr>        <dbl>   <dbl> <dbl> <dbl> <dbl>\n1 arima212012   2.86   -189.  391.  392.  409.\n2 search        2.17   -190.  396.  398.  418.\n3 stepwise      2.25   -193.  399.  400.  418.\n4 arima210011   4.58   -205.  419.  419.  429.\n\n\nOf these models, the best is the ARIMA(2,1,2)(0,1,2)[12]model (i.e., it has the smallest AICc value).\n\n\nShow the code\narima212012 <- tsibble_pdx %>%\n  model(arima212012 = ARIMA(Prices ~ pdq(2,1,2)+ PDQ(0,1,2)))%>%\n  report()\n\n\nSeries: Prices \nModel: ARIMA(2,1,2)(0,1,2)[12] \n\nCoefficients:\n         ar1     ar2     ma1     ma2     sma1    sma2\n      0.5148  0.0355  1.0100  0.9999  -0.8229  0.1287\ns.e.  0.1145  0.1214  0.0582  0.0709   0.1477  0.1514\n\nsigma^2 estimated as 2.856:  log likelihood=-188.55\nAIC=391.09   AICc=392.41   BIC=408.82\n\n\n\n\nShow the code\nall_fit %>% select(arima212012) %>%\n  gg_tsresiduals()\n\n\n\n\n\n\n\nShow the code\naugment(all_fit) %>%\n  filter(.model=='arima212012') %>%\n  features(.innov, ljung_box, lag = 36, dof = 6)\n\n\n# A tibble: 1 × 4\n  RegionName .model      lb_stat lb_pvalue\n  <chr>      <chr>         <dbl>     <dbl>\n1 Portland   arima212012    37.3     0.170\n\n\n\n\nShow the code\ntsibble_pdx %>%\n  model(ARIMA(Prices ~ pdq(2,1,2) + PDQ(0,1,2))) %>%\n  forecast() %>%\n  autoplot(tsibble_pdx) +\n  labs(y=\" Thousands of $US \",\n       x =\" \",\n       title=\"Forecast from the ARIMA(2,1,2)(0,1,2)[12] model\\napplied to the Portland House Prices data\")\n\n\n`mutate_if()` ignored the following grouping variables:\n• Column `year_month`"
  },
  {
    "objectID": "posts/Time-Series/TimeSeries.html#ets",
    "href": "posts/Time-Series/TimeSeries.html#ets",
    "title": "Time Series Project",
    "section": "ETS",
    "text": "ETS\n\n\nShow the code\nfit_ets <- tsibble_pdx %>%\n  model(ETS(Prices))\nreport(fit_ets)\n\n\nSeries: Prices \nModel: ETS(M,Ad,N) \n  Smoothing parameters:\n    alpha = 0.9999 \n    beta  = 0.9987271 \n    phi   = 0.9108026 \n\n  Initial states:\n     l[0]     b[0]\n 407.9964 3.526883\n\n  sigma^2:  0\n\n     AIC     AICc      BIC \n650.8419 651.6904 666.8225 \n\n\nThe model selected is ETS(M,Ad,N)\n\n\nShow the code\ncomponents(fit_ets) %>%\n  autoplot() +\n  labs(title = \"ETS(M,Ad,N) components\")\n\n\nWarning: Removed 1 row containing missing values (`geom_line()`).\n\n\n\n\n\nBecause this model has multiplicative errors, the innovation residuals are not equivalent to the regular residuals.\n\n\nShow the code\nfit_ets %>%\n    augment() %>%\n    select(.innov, .resid) %>%\n    pivot_longer(c(.innov, .resid)) %>%\n    autoplot()\n\n\nPlot variable not specified, automatically selected `.vars = value`\n\n\n\n\n\n\n\nShow the code\nfit_ets%>%\n    gg_tsresiduals()\n\n\n\n\n\n\n\nShow the code\nfit_ets %>%\n  forecast(h = 24) %>%\n  autoplot(tsibble_pdx)\n\n\n`mutate_if()` ignored the following grouping variables:\n• Column `year_month`\n\n\n\n\n\n\n\nShow the code\nbind_rows(\n    arima212012 %>% accuracy(),\n    fit_ets %>% accuracy()) %>%\n  select(-ME, -MPE, -ACF1)\n\n\n# A tibble: 2 × 8\n  RegionName .model      .type     RMSE   MAE  MAPE   MASE  RMSSE\n  <chr>      <chr>       <chr>    <dbl> <dbl> <dbl>  <dbl>  <dbl>\n1 Portland   arima212012 Training  1.53  1.14 0.194 0.0286 0.0310\n2 Portland   ETS(Prices) Training  2.27  1.60 0.271 0.0403 0.0459\n\n\nIn this case the ARIMA model seems to be more accurate model based on the test set RMSE, MAPE and MASE."
  }
]